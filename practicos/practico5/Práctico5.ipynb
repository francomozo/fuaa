{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos de Aprendizaje Automático y Reconocimiento de Patrones\n",
    "***\n",
    "# Práctico 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las bibliotecas que se utilizarán\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "- Implementar desde cero una red neuronal de dos capas\n",
    "- Utilizar la implementación para:\n",
    "    - Clasificar datos sintéticos \n",
    "    - Clasificar entre imágenes de gatos y no gatos\n",
    "- Adquirir cierta intuición sobre las fronteras de decisión determinadas por una red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de ejercicios\n",
    "\n",
    "[Ejercicio 1](#Ejercicio1): implementación de una red neuronal de dos capas       \n",
    "[Ejercicio 2](#Ejercicio2): jugando con tensorflow playground   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio1\"></a>\n",
    "## Ejercicio 1: Implementación de una red neuronal de dos capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notación:\n",
    "\n",
    "- En general, la arquitectura de una red de $L$ capas de define mediante el vector $[d^{(0)},d^{(1)},\\ldots, d^{(L)}]$, siendo $d^{l}$ el número de nodos de la capa $l$.\n",
    "- En una red neuronal de dos capas, es decir con $L=2$, con $l=0$ se referirá a la entrada (no se considera una capa) y con $l=2$ se referirá a la capa de salida.     \n",
    "- A la señal de entrada a la activación $j$ de la capa $l$ se le llamará $s_j^{(l)}$ y a la de salida $x_j^{(l)}$. Así, por ejemplo:\n",
    "    - La coordenada $j$ del vector de características $\\mathbf{x^{(0)}}$ es $x_j^{(0)}$     \n",
    "    - La coordenada $j$ del vector de salida $\\mathbf{x^{(L)}}$ es $x_j^{(L)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones auxiliares (Ejecutar y seguir)\n",
    "def error_relativo(x, y):\n",
    "    ''' devuelve el error relativo'''\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def calcular_gradiente_numerico_array(f, x, df, h=1e-5):\n",
    "    '''\n",
    "    Evalúa el gradiente numérico para una función que acepta un arreglo numpy y\n",
    "    devuelve un arreglo numpy.\n",
    "    '''\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h\n",
    "        pos = f(x).copy()\n",
    "        x[ix] = oldval - h\n",
    "        neg = f(x).copy()\n",
    "        x[ix] = oldval\n",
    "\n",
    "        grad[ix] = np.sum((pos - neg) * df) / (2 * h)\n",
    "        it.iternext()\n",
    "    return grad\n",
    "\n",
    "\n",
    "def calcular_gradiente_numerico(f, x, verbose=True, h=0.00001):\n",
    "    '''\n",
    "    Evalúa el gradiente numérico de f en x\n",
    "    - f es una función que recibe un solo argumente\n",
    "    - x es el punto (numpy array) en que se evalúa el gradiente\n",
    "    '''\n",
    "    \n",
    "    # se inicializa el gradiente \n",
    "    grad = np.zeros_like(x)\n",
    "    # se define un iterador sobre todos los elementos de x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # se evalúa la función en x+h\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h # se suma h al valor original de x\n",
    "        fxph = f(x) # se evalúa f(x + h)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x) # se evalúa f(x - h)\n",
    "        x[ix] = oldval # se restaura el valor original de x\n",
    "\n",
    "        # se calcula la derivada parcial con la fórmula centrada\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h) \n",
    "        if verbose:\n",
    "            print(ix, grad[ix])\n",
    "        it.iternext() # step to next dimension\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementarán algunos de los elementos constitutivos de una red neuronal que más se utilizan en la práctica.  Con ellos se construirán un par de redes neuronales de dos capas. En este ejercicio se limitará la profundidad de la red a 2 para evitar entrar en los detalles de implementación propios de una red muy general. No obstante, los bloques a implementar se diseñaron de forma que conceptualmente sean similares a los que se utilizarían en una red neuronal más profunda. A continuación se muestra un diagrama de bloques de la red neuronal que se implementará y se describen los distintos bloques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/diagrama_de_bloques.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Inicializar parámetros:** Inicializa los parámentros de la red. A los pesos de la capa $l$ de la red le llamaremos $W_l$, $b_l$ con $l=1,2$. \n",
    "- **Propagación hacia adelante:** La *propagación hacia adelante*  o *forward propagation* consiste en estimar la salida de la red a partir de la entrada. Cada nodo o capa de la red tiene un método *forward* asociado. En este ejercicio se implementarán los métodos forward asociados a los siguientes bloques:\n",
    "        - Afin\n",
    "        - Activación \n",
    "        - Afin --> Activación\n",
    "        \n",
    "- **Loss:** Calcula el valor de la función de costo a optimizar. Se implementarán dos funciones de costo:\n",
    "        - Entropía cruzada\n",
    "        - Error cuadrático medio\n",
    "- **Propagación hacia atrás:** Durante la *propagación hacia atrás* o *backpropagation* se calculan los gradientes necesarios para actualizar los parámetros de la red. Se implementarán métodos *backward* para los siguientes bloques:\n",
    "        - Afin\n",
    "        - Activación \n",
    "        - Afin --> Activación\n",
    "- **Update:** Es el boque encargado de actualizar los parámetros. Para ello utiliza los gradientes calculados durante la *propagación hacia atrás* y un método de optimización. En este práctico se utilizará *descenso por gradiente* como método de optimización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Bloque de Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementará el bloque de inicialización para el caso de una red neuronal de dos capas con la siguiente estructura:    \n",
    "  Afín --> Activación 1 --> Afín --> Activacion 2        \n",
    "\n",
    "**Ejercicio:** Completar la implementación de `inicializar_pesos()`. Los pesos $W_l$ serán inicializados en valores aleatorios pequeños. Los pesos correspondientes a términos de *bias* se inicializarán a cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializar_pesos(d_0, d_1, d_2, tipo='aleatoria', std_ruido=0.01, semilla=1):\n",
    "    \"\"\"\n",
    "    Entrada:\n",
    "        d_0: dimensión del vector de características\n",
    "        d_1: número de nodos de la capa oculta\n",
    "        d_2: número de nodos de la capa de salida\n",
    "        tipo: string que indica el tipo de inicialización a utilizar en los pesos\n",
    "            'aleatoria': inicializa los pesos a valores aleatorios con distribución\n",
    "                         gaussiana. Los términos de bias se inicializan a cero.\n",
    "        std_rudio: desviación estandar del ruido gaussiano\n",
    "        semilla: semilla a utilizar para generar los valores aleatorios\n",
    "    \n",
    "    Salida:\n",
    "        diccionario con los siguientes pares clave-valor:\n",
    "            W1: matriz de pesos de la capa 1 de tamaño (d_0, d_1)\n",
    "            b1: vector de bias de la capa 1 de tamaño (d_1)\n",
    "            W2: matriz de pesos de capa 2 de tamaño (d_1, d_2)\n",
    "            b2: vector de bias de la capa 2 de tamaño (d_2)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(semilla)\n",
    "        \n",
    "    if tipo == 'aleatoria':\n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "        W1 = np.random.rand(d_0, d_1)*1e-1\n",
    "        b1 = np.zeros(d_1)\n",
    "        W2 = np.random.rand(d_1, d_2)*1e-1\n",
    "        b2 = np.zeros(d_2)\n",
    "    \n",
    "        ####################################################################################\n",
    "        ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "    \n",
    "    assert(W1.shape == (d_0, d_1 ))\n",
    "    assert(b1.shape == (d_1,))\n",
    "    assert(W2.shape == (d_1, d_2))\n",
    "    assert(b2.shape == (d_2,))\n",
    "    \n",
    "    # Se genera el diccionario con los valores inicializados\n",
    "    parametros = {'W1': W1,\n",
    "                  'b1': b1,\n",
    "                  'W2': W2,\n",
    "                  'b2': b2}\n",
    "    \n",
    "    return parametros    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testeando la incialización aleatoria:\n",
      "Diferencia en W1:  1.0\n",
      "Diferencia en b1:  0.0\n",
      "Diferencia en W2:  1.0\n",
      "Diferencia en b2:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Se testea la inicialización con pesos aleatorios\n",
    "parametros = inicializar_pesos(3,6,1)\n",
    "\n",
    "W1_correcto = np.array([[ 0.01624345, -0.00611756, -0.00528172, -0.01072969,  0.00865408, -0.02301539],\n",
    "                         [ 0.01744812, -0.00761207,  0.00319039, -0.0024937,   0.01462108, -0.02060141],\n",
    "                         [-0.00322417, -0.00384054,  0.01133769, -0.01099891, -0.00172428, -0.00877858]])\n",
    "b1_correcto = np.array([0., 0., 0., 0., 0., 0.])\n",
    "W2_correcto = np.array([[ 0.00042214] , [ 0.00582815], [-0.01100619], [ 0.01144724], [ 0.00901591], [ 0.00502494]])\n",
    "b2_correcto = np.array([0.])\n",
    "\n",
    "# Se compara la salida con la nuestra. El error debería ser e-6 o menos.\n",
    "print('Testeando la incialización aleatoria:')\n",
    "print('Diferencia en W1: ', error_relativo(parametros['W1'], W1_correcto))\n",
    "print('Diferencia en b1: ', error_relativo(parametros['b1'], b1_correcto))\n",
    "print('Diferencia en W2: ', error_relativo(parametros['W2'], W2_correcto))\n",
    "print('Diferencia en b2: ', error_relativo(parametros['b2'], b2_correcto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación:** *La inicialización de pesos en este caso fue aleatoria. Con redes de pocas capas esta inicialización suele producir buenos resultados. Sin embargo, a medida que aumenta la profundidad de la red la correcta inicialización de los parámetros adquiere una relevancia mayor. Quien quiera profundizar en la importancia de la inicialización en el caso de redes profundas puede consultar:* \n",
    "\n",
    "* [Glorot, Xavier, and Yoshua Bengio. “Understanding the difficulty of\n",
    "    training deep feedforward neural networks.” International Conference on Artificial Intelligence and Statistics. 2010.](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "* [He, Kaiming, et al. “Delving deep into rectifiers: Surpassing human-level\n",
    "    performance on imagenet classification.” arXiv preprint arXiv:1502.01852 (2015).](https://arxiv.org/pdf/1502.01852v1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Bloques Forward\n",
    "\n",
    "En esta sección se implementarán los métodos *forward* de los componentes de la red neuronal de dos capas que vamos a utilizar. Observar que la capa oculta tiene un número $d^{(1)}$ de nodos mientras que la de salida tiene 1 un solo nodo. Además observar que en cada nodo se realiza una *transformación afin* de los datos de entrada y luego de pasa el resultado por una *función de activación*.\n",
    "\n",
    "<img src=\"img/red_dos_capas.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En particular, se implementarán los métodos *forward* de los siguientes bloques: \n",
    "\n",
    "- Bloque Afín  \n",
    "- Bloque Activación donde la activación puede ser ReLU, Sigmoide o TangenteH.\n",
    "- Bloque Afín -> Activación  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Forward Afín\n",
    "\n",
    "La señal de entrada a la activación de la capa $\\textit{l}$ puede escribirse como:\n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(l)}=\\left( W^{(l)} \\right)^T \\mathbf{x}^{(l-1)}+ \\mathbf{b}^{(l)}   \\tag{1}\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{s}^{(l)}$ y $\\mathbf{b}^{(l)}$ son vectores de tamaño $d^{(l)}$, $\\mathbf{x}^{(l-1)}$  es un vector de tamaño $d^{(l-1)}$ y $W^{(l)}$ es una matriz de tamaño $d^{(l-1)} \\times d^{(l)}$.\n",
    "\n",
    "**Observación:** *Esta forma de escribir $\\mathbf{s}^{(l)}$ es levemente distinta a la expresión del libro, en la que todos los parámetros de la capa se agrupan en una matriz $W^{(l)}$ de tamaño $d^{(l-1)+1} \\times d^{(l)}$. En esta expresión se desacoplan los parámetros de bias y se indican mediante el vector $\\mathbf{b}^{(l)}$. Una ventaja práctica que tiene desacoplar los parámetros de bias es que $\\mathbf{x}^{(l)}=\\theta \\left(\\mathbf{s}^{(l)}\\right) $ en vez de la expresión en coordenadas homogéneas $\\mathbf{x}^{(l)}= \\left[ 1 , \\left( \\theta \\left(\\mathbf{s}^{(l)}\\right) \\right)^T \\right]^T $ que utiliza el libro del curso.*\n",
    "\n",
    "La ecuación (1) es válida cuando la entrada a la capa es un único vector $\\mathbf{x}^{(l-1)}$. En la práctica es más habitual procesar un $\\textit{batch}$ de vectores de entrada a la vez, por lo tanto es deseable contar con una expresión que genere la salida para todos los vectores de entrada a la vez. Al evitar la utilización de un bloque $\\textit{for}$ que itere por cada una de las muestras del $\\textit{batch}$ se mejora la eficiencia de la implementación.   \n",
    "\n",
    "\n",
    "La versión de la ecuación (1) que actúa sobre un conjunto de muestras a la vez es la siguiente:\n",
    "\n",
    "$$\n",
    "S^{(l)} = X^{(l-1)}W^{(l)} +b^{(l)}\\tag{2}\n",
    "$$\n",
    "\n",
    "donde $X^{[0]} = X$, siendo X una matriz que contiene un vector de características en cada fila.\n",
    "\n",
    "**Ejercicio**: Implementar el método `afin_forward()` utilizando la versión eficiente dada por la ecuación (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_forward(X, W, b):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia adelante en una capa afin.\n",
    "\n",
    "    Entrada:\n",
    "        X: matriz de tamaño (N, dim capa anterior) que en cada fila contiene un vector de\n",
    "           activaciones de la capa anterior (o datos de entrada)\n",
    "        W: matriz de pesos de tamaño (dim de capa anterior, dim de capa actual) \n",
    "        b: vector de bias de tamaño (dim de la capa actual,)\n",
    "\n",
    "    Salida:\n",
    "        S: matriz de tamaño (N, dim de capa actual) que contiene\n",
    "           los scores o señal de entrada a la activación  \n",
    "        cache: (X, W, b) tupla que contiene X, W y b. \n",
    "               Son almacenados para calcular el paso backward eficientemente\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    S = X@W + b\n",
    "\n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    assert(S.shape == (X.shape[0], W.shape[1] ))\n",
    "    cache = (X, W, b)\n",
    "    \n",
    "    return S, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testeando afin_forward:\n",
      "diferencia:  9.769849468192957e-10\n"
     ]
    }
   ],
   "source": [
    "# Se testea afin_forward (solo la salida)\n",
    "\n",
    "num_muestras = 2\n",
    "dim_entrada = 120\n",
    "dim_salida = 3\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=num_muestras * dim_entrada).reshape(num_muestras, dim_entrada)\n",
    "w = np.linspace(-0.2, 0.3, num=dim_entrada *dim_salida ).reshape(dim_entrada, dim_salida)\n",
    "b = np.linspace(-0.3, 0.1, num=dim_salida)\n",
    "\n",
    "S, _ = afin_forward(x, w, b)\n",
    "S_correcto = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
    "\n",
    "# Se compara la salida con la nuestra. El error debería dar e-9 o menos.\n",
    "print('Testeando afin_forward:')\n",
    "print('diferencia: ', error_relativo(S, S_correcto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Funciones de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se implementarán tres de las funciones de activación más utilizadas:\n",
    "\n",
    "- **Sigmoide**: $\\sigma(S) = \\sigma(X W  + b) = \\frac{1}{ 1 + e^{-(X W  + b)}}$. Esta función devuelve, además de la activación resultante, la variable cache que contiene la señal `S` que dio lugar a la activación (se utiilza luego durante la propagación hacia atrás).\n",
    "\n",
    "``` python\n",
    "X, cache = sigmoid(S)\n",
    "```\n",
    "\n",
    "- **Tangente Hiperbólica**: $\\tanh(S) = \\frac{e^S-e^{-S}}{e^S+e^{-S}}$. Esta función devuelve, además del resultado de *np.tanh(S)*, la variable cache que contiene la señal `S` que dio lugar a la activación (se utiilza luego durante la propagación hacia atrás).       \n",
    "\n",
    "``` python\n",
    "X, cache = tanh(S)\n",
    "```\n",
    "\n",
    "\n",
    "- **Rectified Linear Unit**:  $ReLU(S) = max(0, S)$.  Al igual que en el caso de la activación sigmoide, esta función devuelve además de la activación resultante, la variable cache que contiene la señal `S` que dio lugar a la activación (se utiilza luego durante la propagación hacia atrás).\n",
    "\n",
    "``` python\n",
    "X, cache = relu(Z)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(S):\n",
    "    \"\"\"\n",
    "    Implementa la activación sigmoide\n",
    "    \n",
    "    Entrada:\n",
    "        S: arreglo numpy que contiene las entradas a la activación. \n",
    "           Las dimensiones de entrada no están definidas.\n",
    "    \n",
    "    Salida:\n",
    "        X: arreglo del mismo tamaño que S que contiene la salida de sigmoid(S) \n",
    "        cache: devuelve S para utilizar durante la propagación hacia atrás\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    X = 1/(1 + np.exp(-S.copy()))\n",
    "    cache = S.copy()\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    assert X.shape == S.shape, 'La entrada y la salida deben ser del mismo tamaño'\n",
    "    return X, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testeando la función sigmoide()\n",
      "Diferencia:  5.157221295671855e-09\n"
     ]
    }
   ],
   "source": [
    "# Se testea sigmoide() \n",
    "\n",
    "S = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "X, _ = sigmoide(S)\n",
    "X_correcto = np.array([[0.37754067, 0.39913012, 0.42111892, 0.44342513],\n",
    "                         [0.46596182, 0.48863832, 0.51136168, 0.53403818],\n",
    "                         [0.55657487, 0.57888108, 0.60086988, 0.62245933]])\n",
    "\n",
    "# Se compara la salida con la nuestra. El error debería ser del orden de e-8\n",
    "print('Testeando la función sigmoide()')\n",
    "print('Diferencia: ', error_relativo(X, X_correcto))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(S):\n",
    "    \"\"\"\n",
    "    Implementa la activación tangente hiperbólica\n",
    "    \n",
    "    Entrada:\n",
    "        S: arreglo numpy que contiene las entradas a la activación. \n",
    "           Las dimensiones de entrada no están definidas.\n",
    "    \n",
    "    Salida:\n",
    "        X: arreglo del mismo tamaño que S que contiene la salida de tanh(S) \n",
    "        cache: devuelve S para utilizar durante la propagación hacia atrás\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    X = (np.exp(S.copy()) - np.exp(-S.copy()))/(np.exp(S.copy()) + np.exp(-S.copy()))\n",
    "    cache = S.copy()\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    assert X.shape == S.shape, 'La entrada y la salida deben ser del mismo tamaño'\n",
    "    return X, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testeando la función tanh()\n",
      "Diferencia:  3.829228808681821e-08\n"
     ]
    }
   ],
   "source": [
    "# Se testea tanh() \n",
    "\n",
    "S = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "X, _ = tanh(S)\n",
    "X_correcto = np.array([[-0.46211716, -0.38770051, -0.30786199, -0.22343882],\n",
    "                         [-0.13552465, -0.04542327,  0.04542327,  0.13552465],\n",
    "                         [ 0.22343882,  0.30786199,  0.38770051, 0.46211716]])\n",
    "\n",
    "# Se compara la salida con la nuestra. El error debería ser del orden de e-8\n",
    "print('Testeando la función tanh()')\n",
    "print('Diferencia: ', error_relativo(X, X_correcto))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(S):\n",
    "    '''\n",
    "    Implementa la activación relu\n",
    "    \n",
    "    Entrada:\n",
    "        S: arreglo numpy que contiene las entradas a la activación. \n",
    "           Las dimensiones de entrada no están definidas.\n",
    "    \n",
    "    Salida:\n",
    "        X: arreglo del mismo tamaño que S que contiene la salida de relu(S) \n",
    "        cache: devuelve S para utilizar durante la propagación hacia atrás\n",
    "    '''\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    X = S.copy()*0\n",
    "    \n",
    "    for i in range(S.shape[0]): \n",
    "        for j in range(S.shape[1]):\n",
    "            if S[i,j] > 0:\n",
    "                X[i,j] = S[i,j].copy()\n",
    "        \n",
    "    cache = S.copy()\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    assert(X.shape == S.shape)\n",
    "        \n",
    "    return X, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testeando la función relu()\n",
      "Diferencia:  4.999999798022158e-08\n"
     ]
    }
   ],
   "source": [
    "# Testeando la función relu()\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "X, _ = relu(x)\n",
    "X_correcto = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Se compara la salida con la nuestra. El error debería ser del orden de e-8\n",
    "print('Testeando la función relu()')\n",
    "print('Diferencia: ', error_relativo(X, X_correcto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Aplicación conjunta de capa afin y activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se implementan redes profundas es conveniente agrupar varias funciones en una sola operación. Para ejemplificar, en este caso crearemos una capa que aplique la transformación lineal y una de las activaciones disponibles. \n",
    "\n",
    "**Ejercicio**: Implementar la propagación hacia adelante de una capa *Afin->Activacion*. El método `afin_activacion_forward()` implementa la operación:\n",
    "\n",
    "$$\n",
    "X^{[l]} = \\theta(S^{(l)}) = \\theta(X^{(l-1)}W^{(l)} +b^{(l)})\n",
    "$$\n",
    "\n",
    "donde la activación $\\theta(\\cdot)$ será alguna de las implementadas. Se deberá hacer uso de `afin_forward()` y de la función de activación pasada como argumento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_activacion_forward(X_prev, W, b, activacion):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia adelante para una capa Afin->Activación \n",
    "    Entrada:\n",
    "        X_prev: arreglo de tamaño (N, dim capa anterior) que contiene la \n",
    "                activación de la capa anterior (o datos de entrada):          \n",
    "        W: matriz de pesos de tamaño (dim de capa anterior, dim de capa actual)  \n",
    "        b: vector de bias de tamaño (dim de la capa actual)\n",
    "        activacion: la activacion a utilizar en esta capa se indica con uno de los \n",
    "                    siguientes strings: 'sigmoide', 'tanh' o 'relu'\n",
    "\n",
    "    Salida:\n",
    "        X: arreglo de tamaño (N, dim de capa actual) que contiene la salida \n",
    "           de la función de activación  \n",
    "        cache: tupla que contiene \"cache_afin\" y \"cache_activacion\".\n",
    "               Se almacenan para calcular la propagación hacia atrás eficientemente\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    S, cache_afin = afin_forward(X_prev, W, b)\n",
    "        \n",
    "    if activacion == 'sigmoide':\n",
    "        X, cache_activacion = sigmoide(S)\n",
    "    elif activacion == 'tanh':\n",
    "        X, cache_activacion = tanh(S)\n",
    "    elif activacion == 'relu':\n",
    "        X, cache_activacion = relu(S)\n",
    "    \n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    assert (X.shape == (X_prev.shape[0], W.shape[1]))\n",
    "    cache = (cache_afin, cache_activacion)\n",
    "\n",
    "    return X, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testeando afin_activacion_forward con activación sigmoide:\n",
      "diferencia:  2.8286980165180753e-09\n",
      "Testeando afin_activacion_forward con activación tanh:\n",
      "diferencia:  5.346405168705657e-09\n",
      "Testeando afin_activacion_forward con activación relu:\n",
      "diferencia:  2.870847555008169e-09\n"
     ]
    }
   ],
   "source": [
    "# Se testea afin_activacion_forward (solo la salida)\n",
    "\n",
    "num_muestras = 3\n",
    "dim_entrada = 80\n",
    "dim_salida = 2\n",
    "\n",
    "x_prev = np.linspace(-0.1, 0.5, num=num_muestras * dim_entrada).reshape(num_muestras, dim_entrada)\n",
    "w = np.linspace(-0.2, 0.3, num=dim_entrada *dim_salida ).reshape(dim_entrada, dim_salida)\n",
    "b = np.linspace(-0.3, 0.1, num=dim_salida)\n",
    "\n",
    "\n",
    "print('Testeando afin_activacion_forward con activación sigmoide:')\n",
    "X, _ = afin_activacion_forward(x_prev, w, b, 'sigmoide')\n",
    "X_correcto = np.array([[0.59153611, 0.6835444 ],\n",
    "                       [0.75921928, 0.8318392 ],\n",
    "                       [0.87286027, 0.91888762]])\n",
    "# Se compara la salida con la nuestra. El error debería dar  del orden de e-9.\n",
    "print('diferencia: ', error_relativo(X, X_correcto))\n",
    "\n",
    "\n",
    "print('Testeando afin_activacion_forward con activación tanh:')\n",
    "X, _ = afin_activacion_forward(x_prev, w, b, 'tanh')\n",
    "X_correcto = np.array([[0.35427088, 0.64699264],\n",
    "                       [0.81722466, 0.92147542],\n",
    "                       [0.95844863, 0.98453647],])\n",
    "# Se compara la salida con la nuestra. El error debería dar  del orden de e-9.\n",
    "print('diferencia: ', error_relativo(X, X_correcto))\n",
    "\n",
    "\n",
    "print('Testeando afin_activacion_forward con activación relu:')\n",
    "X, _ = afin_activacion_forward(x_prev, w, b, 'relu')\n",
    "X_correcto = np.array([[[0.3703192,  0.77010868],\n",
    "                        [1.14840399, 1.59871845],\n",
    "                        [1.92648878, 2.42732823]],])\n",
    "\n",
    "# Se compara la salida con la nuestra. El error debería dar  del orden de e-9.\n",
    "print('diferencia: ', error_relativo(X, X_correcto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Función de costo\n",
    "\n",
    "En esta sección se implementarán dos de las funciones de costo más utilizadas.  \n",
    "\n",
    "- **Entropía cruzada:** Es la función de costo más utilizada en problemas de clasificación binaria. Se recuerda que la misma se define mediante la fórmula:\n",
    "$$\n",
    "H(\\mathbf{\\mathbf{x}^{(L)}}, \\mathbf{y})= -\\frac{1}{N} \\sum\\limits_{n = 1}^{N} \\left( y_n\\log x^{(L)}_n + (1-y_n)\\log\\left(1- x^{(L)}_n\\right) \\right) \\tag{3}\n",
    "$$\n",
    "\n",
    "- **Error cuadrático medio:** Es la función de costo más utilizada en problemas de regresión. Se recuerda que la misma se define mediante la fórmula:\n",
    "$$\n",
    "MSE(\\mathbf{x}^{(L)}, \\mathbf{y})= \\frac{1}{2N} \\sum\\limits_{n = 1}^{N} \\left(y_n - x^{(L)}_n \\right)^2 \\tag{4}\n",
    "$$\n",
    "**Ejercicio**: Implementar los método `mse()` y `entropia_cruzada()`. Observar que en ambos casos la función deberá devolver, además del costo, el gradiente del costo respecto al vector $\\mathbf{x}^{(L)}$ (salida de la red y entrada del bloque *Loss*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(xL, y):\n",
    "    \"\"\"\n",
    "    Implementa el error cuadratico medio como función de costo de una red neuronal con una sola capa\n",
    "    de salida.\n",
    "\n",
    "    Entrada:\n",
    "        xL: vector de dimensión (N,1) que contiene las salidas generadas por la red neuronal para N muestras.\n",
    "        y:  vector de dimensión (N,1) que contiene las salidas esperadas\n",
    "\n",
    "    Salida:\n",
    "        costo: escalar con el costo calculado\n",
    "        dxL: gradiente del costo respecto a xL, tiene las mismas dimensiones que xL\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(y)\n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    costo = 0\n",
    "    \n",
    "    for n in range(1,N):\n",
    "        costo -= (y[n] - xL[n])**2\n",
    "    \n",
    "    costo = costo/N\n",
    "\n",
    "    dxL = 0\n",
    "    for n in range(1,N):\n",
    "        costo -= y[n]*np.log(xL[n]) + (1-y[n])*np.log(1-xL[n])\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    costo = np.squeeze(costo) # Para asegurarnos que la salida sea un escalar (Ej: transforma [[12]] en 12).\n",
    "    assert(costo.shape == ())\n",
    "    assert(dxL.shape == xL.shape), 'Las dimensiones de dxL y xL deben ser iguales'\n",
    "    return costo, dxL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-fd06bc3e13e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdxL_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalcular_gradiente_numerico\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mxL\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mcosto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-83d4eec084ab>\u001b[0m in \u001b[0;36mcalcular_gradiente_numerico\u001b[1;34m(f, x, verbose, h)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0moldval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moldval\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m \u001b[1;31m# se suma h al valor original de x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mfxph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# se evalúa f(x + h)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moldval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mfxmh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# se evalúa f(x - h)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-fd06bc3e13e3>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(xL)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdxL_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalcular_gradiente_numerico\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mxL\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mcosto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-98f46e960b9d>\u001b[0m in \u001b[0;36mmse\u001b[1;34m(xL, y)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mcosto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosto\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Para asegurarnos que la salida sea un escalar (Ej: transforma [[12]] en 12).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdxL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mxL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Las dimensiones de dxL y xL deben ser iguales'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcosto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Se testea la implementación de la función de costo error cuadrático medio\n",
    "np.random.seed(43)\n",
    "num_inputs = 9\n",
    "xL = np.random.rand(num_inputs,1)\n",
    "y = np.random.rand(num_inputs,1)\n",
    "\n",
    "dxL_num = calcular_gradiente_numerico(lambda xL: mse(xL, y)[0], xL, verbose=False)\n",
    "costo, dxL = mse(xL, y)\n",
    "\n",
    "# Testing de mse(). El costo debería dar cercano a 0.069 y el error en dxL en el entorno de e-10\n",
    "print('\\nTesting mse():')\n",
    "print('costo: ', costo)\n",
    "print('error en dxL: ', error_relativo(dxL_num, dxL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia_cruzada(xL, y):\n",
    "    \"\"\"\n",
    "    Implementa la entropía cruzada\n",
    "\n",
    "    Entrada:\n",
    "        xL: vector de dimensión (N,1) que contiene las ¨probabilidades¨ de pertenecer a la clase positiva \n",
    "            estimadas por el modelo\n",
    "        y: vector de etiquetas de dimesión (N,1) (con unos para la clase positiva y 0 para la negativa)\n",
    "\n",
    "    Salida:\n",
    "        costo: escalar con el costo calculado\n",
    "        dxL: gradiente del costo respecto a xL, tiene las mismas dimensiones que xL\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(y)\n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    costo = 0\n",
    "    \n",
    "    for n in range(1,N):\n",
    "        costo -= y[n]*np.log(xL[n]) + (1-y[n])*np.log(1-xL[n])\n",
    "    costo = costo/N\n",
    "\n",
    "    dxL = xL.copy()*0\n",
    "    \n",
    "    for n in range(1,N):\n",
    "        dxL -= y[n]/xL[n] - (1-y[n])/(1-xL[n])        \n",
    "    dxL = dxL/N\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    costo = np.squeeze(costo) # Para asegurarnos que la salida sea un escalar (Ej: transforma [[12]] en 12).\n",
    "    assert(costo.shape == ())\n",
    "    assert(dxL.shape == xL.shape), 'Las dimensiones de dxL y xL deben ser iguales'\n",
    "    return costo, dxL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing entropia_cruzada:\n",
      "costo:  1.0321568484869208\n",
      "error en dP:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Se testea la implementación de la entropía cruzada\n",
    "np.random.seed(231)\n",
    "num_classes, num_inputs = 2, 10\n",
    "xL = np.random.rand(num_inputs,1)\n",
    "y = np.random.randint(num_classes, size=(num_inputs,1))\n",
    "\n",
    "dxL_num = calcular_gradiente_numerico(lambda xL: entropia_cruzada(xL, y)[0], xL, verbose=False)\n",
    "costo, dxL = entropia_cruzada(xL, y)\n",
    "\n",
    "# Testing la entropía cruzada. El costo debería dar cercano a 1.05 y el error en dP alrededor de 1e-8\n",
    "print('\\nTesting entropia_cruzada:')\n",
    "print('costo: ', costo)\n",
    "print('error en dP: ', error_relativo(dxL_num, dxL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Propagación hacia atrás\n",
    "\n",
    "Al igual que como se hizo con la propagación hacia adelante, se implementarán funciones de ayuda para realizar la propagación hacia atrás. Se recuerda que la propagación hacia atrás se utiliza para calcular el gradiente de la función de costo respecto a los parámetros de la red. \n",
    "\n",
    "<img src=\"img/diagrama_backpropagation.png\" style=\"width:8=1012px;height:223px;\">\n",
    "<caption><center> Propagación hacia adelante y atrás en una red de dos capas con arquitectura: Afin->Activación 1->Afin->Activación 2 <br> </center></caption>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se implementará la versión *backward* de cada una de las funciones *forward* implementadas anteriormente. Es decir, se implementarán las siguientes funciones de propagación hacia atrás:\n",
    "- AFIN backward\n",
    "- ACTIVACION backward \n",
    "- AFIN -> ACTIVACION backward donde ACTIVACION puede ser *ReLU*, *sigmoide* o *tanh*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Afin backward\n",
    "\n",
    "Durante la propagación hacia adelante en la capa $l$ (sin considerar la activación) se calcula para una muestra: \n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(l)}=\\left( W^{(l)} \\right)^T \\mathbf{x}^{(l-1)}+ \\mathbf{b}^{(l)}   \\tag{1}\n",
    "$$\n",
    "\n",
    "Si se llama $e_n$ al costo debido a la muesta $n$ y se asume conocido el *vector de sensibilidad* $\\delta^{(l)}=\\frac{\\partial e_n}{\\partial \\mathbf{s}^{(l)}}$, en el teórico del curso se vio que \n",
    "\n",
    "$$\n",
    "\\frac{\\partial{e_n}}{\\partial{W^{(l)}}}=\\mathbf{x}^{(l-1)} \\left( \\delta^{(l)} \\right)^T\n",
    "$$\n",
    "\n",
    "Análogamente a como se hizo en el caso de la propagación hacia adelante, si se considera la contribución al error de un conjunto de muestras a la vez la ecuación se puede escribir en forma vectorizada como:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{E}}{\\partial{W^{(l)}}}= dW^{(l)} = \\left( X^{(l-1)}\\right)^ T dS^{(l)}   \\tag{5}\n",
    "$$\n",
    "\n",
    "donde $dS^{(l)}$ es una matríz de tamaño $N\\times d^{(l)}$ que en cada fila contiene el vector de sensibilidad $\\delta^{(l)}_n$ correspondiente a una de las muestras.\n",
    "\n",
    "Las derivadas respecto al vector de bias $\\mathbf{b}^{(l)}$ se calculan de forma similar (puede pensarse como un caso particular en que $X^{(l-1)}$ es un vector columna de unos) por lo que\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{E}}{\\partial{\\mathbf{b}^{(l)}}}= d\\mathbf{b}^{(l)} =\\mathbb{1} ^ T dS^{(l)}  \\tag{6}\n",
    "$$\n",
    "\n",
    "Finalmente se calcula la influencia de cada una de las características en el error. Considerando primero el caso de una muestra, se tiene que:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{e_n}}{\\partial{\\mathbf{x}^{(l-1)}}} = W^{(l)} \\delta^{(l)}\n",
    "$$\n",
    "\n",
    "que en forma vectorizada puede escribirse como:\n",
    "\n",
    "$$ \n",
    " \\frac{\\partial E }{\\partial X^{(l-1)}} = dX^{(l-1)} = dS^{(l)} \\left( W^{(l) }\\right)^T \\tag{7}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Ejercicio**: Utilizando las ecuaciones (5),(6) y (7) implementar el método `afin_backward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_backward(dS, cache):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia atrás para una capa l (sin considerar la activación)\n",
    "\n",
    "    Entrada:\n",
    "        dS: Gradiente de la función de costo con respecto a la salida de la capa actual \n",
    "            (sin considerar la activación)\n",
    "        cache: tupla de valores (X_prev, W, b) calculados durante la propagación hacia adelante\n",
    "               de la capa actual\n",
    "\n",
    "    Salida:\n",
    "        dX_prev: Gradiente de la función de costo con respecto a la activación de la capa anterior (l-1), \n",
    "                 tiene el mismo tamaño que X_prev\n",
    "        dW: Gradiente de la función de costo con respecto a W (de la capa actual l), \n",
    "            tiene el mismo tamaño que W\n",
    "        db: Gradiente de la función de costo con respecto a b (de la capa actual l), \n",
    "            tiene el mismo tamaño que b\n",
    "    \"\"\"\n",
    "    X_prev, W, b = cache\n",
    "    N = X_prev.shape[0]\n",
    "\n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    ones = np.ones(dS.shape[0])\n",
    "    \n",
    "    dW = np.transpose(X_prev)@dS\n",
    "    db = np.transpose(ones)@dS\n",
    "    dX_prev = dS@np.transpose(W)\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    assert (dX_prev.shape == X_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dX_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing afin_backward():\n",
      "dx error:  3.669042497648924e-09\n",
      "dw error:  3.7482312588464514e-11\n",
      "db error:  1.640806364146397e-11\n"
     ]
    }
   ],
   "source": [
    "# Test de afin_backward\n",
    "np.random.seed(43)\n",
    "x = np.random.randn(10, 6)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = calcular_gradiente_numerico_array(lambda x: afin_forward(x, w, b)[0], x, dout)\n",
    "dw_num = calcular_gradiente_numerico_array(lambda w: afin_forward(x, w, b)[0], w, dout)\n",
    "db_num = calcular_gradiente_numerico_array(lambda b: afin_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = afin_forward(x, w, b)\n",
    "dx, dw, db = afin_backward(dout, cache)\n",
    "\n",
    "# El error debería ser del orden de e-9 o menos\n",
    "print('Testing afin_backward():')\n",
    "print('dx error: ', error_relativo(dx_num, dx))\n",
    "print('dw error: ', error_relativo(dw_num, dw))\n",
    "print('db error: ', error_relativo(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Activación backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si  $\\theta(\\cdot)$ es la función de activación, entonces tanto\n",
    "`sigmoide_backward()` como `tanh_backward()` y `relu_backward()` calculan \n",
    "\n",
    "$$\n",
    "dS^{(l)} = dX^{(l)} * \\theta'(S^{(l)})   \\tag{8}\n",
    "$$.  \n",
    "\n",
    "donde $\\theta'(\\cdot)$ debe ser calculado para cada caso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: Implementar los métodos *backward* cada una de las funciones de activación implementadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_backward(dX, cache):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia atrás de una activación tanh().\n",
    "\n",
    "    Entrada:\n",
    "        dX: gradiente de la función de costo respecto a la salida de la capa tanh(),\n",
    "              el tamaño del arreglo no está definido\n",
    "        cache: 'S' valor almacenado durante la propagación hacia adelante\n",
    "\n",
    "    Returns:\n",
    "        dS: Gradiene del costo respecto a S\n",
    "    \"\"\"\n",
    "    \n",
    "    S = cache\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    dS\n",
    "     \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    assert (dS.shape == S.shape), 'dS y S no tienen el mismo tamaño'\n",
    "    assert (dX.shape == S.shape), 'dX y S no tienen el mismo tamaño'\n",
    "    \n",
    "    return dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de tanh_backward\n",
    "\n",
    "np.random.seed(231)\n",
    "S = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*S.shape)\n",
    "\n",
    "dS_num = calcular_gradiente_numerico_array(lambda S: tanh(S)[0], S, dout)\n",
    "\n",
    "_, cache = tanh(S)\n",
    "dS = tanh_backward(dout, cache)\n",
    "\n",
    "# El error debería ser del orden de e-10\n",
    "print('Testing tanh_backward():')\n",
    "print('dS error: ', error_relativo(dS_num, dS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide_backward(dX, cache):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia atrás de una activación Sigmoide.\n",
    "\n",
    "    Entrada:\n",
    "        dX: gradiente de la función de costo respecto a la salida de la capa relu,\n",
    "              el tamaño del arreglo no está definido\n",
    "        cache: 'S' valor almacenado durante la propagación hacia adelante\n",
    "\n",
    "    Returns:\n",
    "    dS -- Gradiene del costo respecto a S\n",
    "    \"\"\"\n",
    "    \n",
    "    S = cache\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    # dS = \n",
    "     \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    assert (dS.shape == S.shape), 'dS y S no tienen el mismo tamaño'\n",
    "    assert (dX.shape == S.shape), 'dX y S no tienen el mismo tamaño'\n",
    "    \n",
    "    return dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de sigmoid_backward\n",
    "np.random.seed(231)\n",
    "S = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*S.shape)\n",
    "\n",
    "dS_num = calcular_gradiente_numerico_array(lambda S: sigmoide(S)[0], S, dout)\n",
    "\n",
    "_, cache = sigmoide(S)\n",
    "dS = sigmoide_backward(dout, cache)\n",
    "\n",
    "# El error debería ser del orden de e-10 o menos\n",
    "print('Testing relu_backward():')\n",
    "print('dS error: ', error_relativo(dS_num, dS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dX, cache):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia atrás de una activación ReLu.\n",
    "\n",
    "    Entrada:\n",
    "        dX: gradiente de la función de costo respecto a la salida de la capa relu,\n",
    "              el tamaño del arreglo no está definido\n",
    "        cache: 'S' valor almacenado durante la propagación hacia adelante\n",
    "\n",
    "    Returns:\n",
    "    dS -- Gradiene del costo respecto a S\n",
    "    \"\"\"\n",
    "    \n",
    "    S = cache\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    # dS = \n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    assert (dS.shape == S.shape)\n",
    "    \n",
    "    return dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dS_num = calcular_gradiente_numerico_array(lambda x: relu(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu(x)\n",
    "dS = relu_backward(dout, cache)\n",
    "\n",
    "# El error debería ser del orden de e-12\n",
    "print('Testing relu_backward():')\n",
    "print('dS error: ', error_relativo(dS_num, dS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Afin --> Activacion backward\n",
    "\n",
    "A continuación se implementará la función que realiza la propagación hacia atrás del la capa *Afin-->Activacion*. \n",
    "\n",
    "**Ejercicio**: Implementar la función `afin_activacion_backward()`. Para ello utilizar las funciones implementadas anteriormente: `afin_backward` y la ¨`activacion_backward`¨ que corresponda. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_activacion_backward(dX, cache, activacion):\n",
    "    '''\n",
    "    Implementar la propagación hacia atrás para la capa Afin->Activacion.\n",
    "    \n",
    "    Entradas:\n",
    "        dX: gradiente del costo respecto a la salida de la capa actual \n",
    "        cache: tupla con los valores(cache_afin, cache_activacion) \n",
    "        activacion: la activación a utilizar en esta capa, puede ser 'sigmoide', 'tanh' o 'relu'\n",
    "    Salidas:\n",
    "        dX_prev: Gradiente del costo con respecto a la activación de la capa anterior(l-1), \n",
    "                 tiene las mismas dimensiones que X_prev\n",
    "        dW -- Gradiente del costo con respecto a W (de la capa actual l), \n",
    "              tiene las mismas dimensiones que W\n",
    "        db -- Gradiente del costo con respecto a b (de la capa actual l), \n",
    "              tiene las mismas dimensiones que b\n",
    "    '''\n",
    "    cache_afin, cache_activacion = cache\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    return dX_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 12)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "activaciones = ['relu', 'sigmoide','tanh']\n",
    "\n",
    "for activacion in activaciones:\n",
    "    out, cache = afin_activacion_forward(x, w, b, activacion)\n",
    "    dx, dw, db = afin_activacion_backward(dout, cache, activacion)\n",
    "\n",
    "    dx_num = calcular_gradiente_numerico_array(lambda x: afin_activacion_forward(x, w, b, activacion)[0], x, dout)\n",
    "    dw_num = calcular_gradiente_numerico_array(lambda w: afin_activacion_forward(x, w, b, activacion)[0], w, dout)\n",
    "    db_num = calcular_gradiente_numerico_array(lambda b: afin_activacion_forward(x, w, b, activacion)[0], b, dout)\n",
    "\n",
    "    # Los errores deberían ser del orden de e-9 o menos\n",
    "    print('Testing afin_' + activacion + '_forward y afin_' + activacion + '_backward:')\n",
    "    print('dx error: ', error_relativo(dx_num, dx))\n",
    "    print('dw error: ', error_relativo(dw_num, dw))\n",
    "    print('db error: ', error_relativo(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5 - Actualización de los parámetros\n",
    "\n",
    "En esta sección se actualizarán los parámetros del modelo mediante el método de *descenso por gradiente*:\n",
    "\n",
    "$$ W^{(l)} = W^{(l)} -\\eta \\text{ } dW^{(l)} \\tag{9}$$\n",
    "$$ \\mathbf{b}^{(l)} = \\mathbf{b}^{(l)} -\\eta \\text{ } \\mathbf{db}^{(l)} \\tag{10}$$\n",
    "\n",
    "donde $\\eta$ es el *learning rate*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: Implementar `actualizar_parametros()` para actualizar los parámetros usando *descenso por gradiente*. Luego de actualizar los parámetros, almacenarlos en el diccionario de parámetros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_parametros(parametros, gradientes, learning_rate):\n",
    "    \"\"\"\n",
    "    Se actualizan los parámetros utilizando descenso por gradiente. Si bien en este notebook se trabaja \n",
    "    con una red de dos capas, el método se implementa en forma genérica para mostrar como se haría en el\n",
    "    caso más general.\n",
    "    \n",
    "    Entrada:\n",
    "        parametros: diccionario de python que contiene los parámetros \n",
    "        gradientes: diccionario de python que contiene los gradientes \n",
    "                    (las salidas de los métodos backward)\n",
    "    \n",
    "    Salida:\n",
    "        parametros: diccionario de python que contiene los parámetros actualizados \n",
    "                    parametros[\"W\" + str(l)] = ... \n",
    "                    parametros[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parametros) // 2 # número de capas en la red neuronal\n",
    "    \n",
    "    # Se actualiza cada uno de los parámetros. En el caso de una red profunda de L capas\n",
    "    # se hace con un loop que va recorriendo cada parámetro\n",
    "    for l in range(1,L+1):\n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "        \n",
    "\n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación utilizando datos sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aux_datos import  generar_flor, mostrar_frontera_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan datos sintéticos con forma de flor pertenecientes a dos clases: $cero$ y $uno$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y = generar_flor()\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se muestran los datos\n",
    "plt.scatter(X[:,0], X[:,1], c=Y.flatten(), s=40, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red para clasificar los datos sintéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para clasificar los datos sintéticos se utilizará una red de dos capas con la siguiente arquitectura:   \n",
    "\n",
    "*Afin->Tanh->Afin->Sigmoide* \n",
    "\n",
    "**Ejercicio:** Completar la implementación de los métodos `red_dos_capas_datos_sinteticos()` utilizando los métodos *forward* y *backward* adecuados para dicha arquitectura. Como función de costo se utilizará la *entropía cruzada*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_dos_capas_datos_sinteticos(X, Y, dims_capas, num_iter = 1000, learning_rate = 1,\n",
    "                                   mostrar_costo=False, semilla=100):\n",
    "    \"\"\"\n",
    "    Implementa una red neuronal de dos capas: Afin->Tanh->Afin->Sigmoide.\n",
    "    \n",
    "    Entrada:\n",
    "        X: datos de entrada, de tamaño (N, d_0)\n",
    "        Y: etiquetas (1 para la clase positiva y 0 para la negativa), de tamaño (N,1)\n",
    "        dims_capas: dimensiones de las capas(d_0, d_1, d_2)\n",
    "        num_iter: número de iteraciones del loop de optimización\n",
    "        learning_rate: learning rate utilizado para la actualización mediante descenso por gradiente\n",
    "        mostrar_costo: Si vale True, se muestra el costo cada 100 iteraciones \n",
    "        semilla: semilla utilizada para la generación de números aleatorios \n",
    "    Salida:\n",
    "        parametros: un diccionario de python que contiene W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(semilla)\n",
    "    gradientes = {} # se inicializa el diccionario que almacena los gradiantes\n",
    "    costos = []     # lista que almacena el costo\n",
    "    N = X.shape[0]  # número de muestras\n",
    "    d_0, d_1, d_2 = dims_capas  \n",
    "    \n",
    "    # Se inicializan los parámetros del diccionario llamando a una de las \n",
    "    # funciones previamente implementadas\n",
    "    parametros = inicializar_pesos(d_0, d_1, d_2, semilla=semilla)\n",
    "     \n",
    "    # Se obtienen W1, b1, W2 y b2 del diccionario de parámetros.\n",
    "    W1 = parametros[\"W1\"]\n",
    "    b1 = parametros[\"b1\"]\n",
    "    W2 = parametros[\"W2\"]\n",
    "    b2 = parametros[\"b2\"]\n",
    "    \n",
    "    # Loop (descenso por gradiente)\n",
    "\n",
    "    for i in range(0, num_iter):\n",
    "\n",
    "        ####################################################################################\n",
    "        ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "        \n",
    "        # Propagación hacia adelante: Afin -> Tanh -> Afin -> Sigmoide. \n",
    "        # Entradas: \"X, W1, b1\". Salidas: \"X1, cache1, X2, cache2\".\n",
    "\n",
    "        \n",
    "        # Se calcula el costo y se inicia la propagación hacia atrás\n",
    "\n",
    "        \n",
    "        # Propagación hacia atrás. \n",
    "        # Entradas: \"dX2, cache2, cache1\". Salidas: \"dX1, dW2, db2, dW1, db1, dX0 (no utilizado)\".\n",
    "        # print('dX2 shape:', dX2.shape)\n",
    "\n",
    "\n",
    "        # Se almacenan los gradientes recientemente calculados en el diccionario \n",
    " \n",
    "        \n",
    "        # Se actualizan los parámetros\n",
    "\n",
    "        \n",
    "        # Se obtienen los nuevos W1, b1, W2 y b2 del diccionario de parámetros.\n",
    "        \n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "\n",
    "        # Se muestra la evolución del costo cada 100 iteraciones\n",
    "        if mostrar_costo and i % 100 == 0:\n",
    "            print(\"Costo luego de iteracion {}: {}\".format(i, np.squeeze(costo)))\n",
    "\n",
    "        if mostrar_costo and i % 100 == 0:\n",
    "            costos.append(costo)\n",
    "         \n",
    "    # se muestra el costo\n",
    "    plt.plot(np.squeeze(costos))\n",
    "    plt.ylabel('costo')\n",
    "    plt.xlabel('iteraciones (sobre 100)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Se definen las constantes que determinan la arquitectura de la red ####\n",
    "d_0 = X.shape[1]   \n",
    "d_1 = 4\n",
    "d_2 = 1\n",
    "dims_capas = [d_0, d_1, d_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se entrena la red, con los parámetros por defecto el costo debería ser alrededor de 0.69 en la iteración 0 y \n",
    "# menor que 0.25 en la 10000\n",
    "parametros_red_2capas_datos_sinteticos = red_dos_capas_datos_sinteticos(X, Y, dims_capas = [d_0, d_1, d_2], \n",
    "                                                                        num_iter = 10000, mostrar_costo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar la frontera de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mostrar la frontera de decisión se deberá completar primero la implementación del método `predecir_clase_datos_sinteticos()`. Dicho método utiliza los parámetros de la red recientemente encontrados para predecir la clase de los vectores de características pasados como parámetro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_clase_datos_sinteticos(X, parametros):\n",
    "    \"\"\"\n",
    "    Esta función predice la clase de los datos sintéticos. \n",
    "    \n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nx2 que en cada fila contiene un vector de características\n",
    "        parametros: parametros del modelo ya entrenado\n",
    "    \n",
    "    Salida:\n",
    "        p : vector de tamaño Nx1 que contiene las predicciones realizadas (0 o 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Se obtienen W1, b1, W2 y b2 del diccionario de parámetros.\n",
    "    W1 = parametros[\"W1\"]\n",
    "    b1 = parametros[\"b1\"]\n",
    "    W2 = parametros[\"W2\"]\n",
    "    b2 = parametros[\"b2\"]\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    p = np.zeros((N,1))\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    # Se hace la propagación hacia adelante de los datos de entrada X. Tener en cuenta que la\n",
    "    # arquitectura utilizada en la red fue Afin-->Tanh-->Afin-->Sigmoide\n",
    "    # ~ 2 lineas de codigo\n",
    "\n",
    "\n",
    "    # Se obtienen las predicciones. Si la salida es mayor que 0.5 se asigna la clase 1, de lo \n",
    "    # contrario se asigna 0\n",
    "    # ~ 1 linea de codigo\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda muestra el porcentaje de acierto con el conjunto de entrenamiento. Verificar que para los parámetros por defecto es mayor al 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_train = predecir_clase_datos_sinteticos(X, parametros_red_2capas_datos_sinteticos)\n",
    "porcentaje_aciertos = np.mean(predicciones_train==Y)\n",
    "print('El porcentaje de aciertos es %f' % porcentaje_aciertos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra la frontera de decisión. Verificar que es razonable para el conjunto de entrenamiento.\n",
    "mostrar_frontera_decision(lambda x: predecir_clase_datos_sinteticos(x, parametros_red_2capas_datos_sinteticos), X, Y.flatten())\n",
    "plt.title('Frontera de decisión para una capa oculta de ' + str(d_1) + ' nodos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** Variar la cantidad de nodos utilizados en la capa oculta y comentar sobre la influencia de dicho parámetro en la superficie de decisión obtenida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**  \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de imágenes\n",
    "\n",
    "Se utilizarán las funciones implementadas anteriormente para distinguir imágenes de *gatos* de *no gatos*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda carga los datos. La base cuenta con conjunto de imágenes para entrenamiento y un conjunto para test. En este caso las características a utilizar son directamente los valores de los píxeles de las imágenes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se levantaron 209 imágenes de entrenamiento\n",
      "72 pertenecen a la clase non-cat y 137 a la clase cat\n",
      "Se levantaron 50 imágenes de test\n",
      "33 pertenecen a la clase non-cat y 17 a la clase cat\n",
      "Las imágenes son de tamaño [64, 64, 3] \n"
     ]
    }
   ],
   "source": [
    "from aux_datos import load_cats_dataset\n",
    "features_train, y_train, features_test, y_test, clases = load_cats_dataset()\n",
    "print('Se levantaron %d imágenes de entrenamiento' % len(features_train))\n",
    "print('%d pertenecen a la clase %s y %d a la clase %s' % (np.sum(y_train==1),clases[0].decode(\"utf-8\"),\n",
    "                                                          np.sum(y_train==0),clases[1].decode(\"utf-8\"))  )\n",
    "print('Se levantaron %d imágenes de test' % len(features_test))\n",
    "print('%d pertenecen a la clase %s y %d a la clase %s' % (np.sum(y_test==1),clases[0].decode(\"utf-8\"),\n",
    "                                                          np.sum(y_test==0),clases[1].decode(\"utf-8\"))  )\n",
    "\n",
    "print('Las imágenes son de tamaño [%d, %d, %d] ' % (features_train.shape[1:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada vez que se ejecuta la siguiente celda se muestra un ejemplo de cada una de las clases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de una imagen gato\n",
    "indices_gatos = [i for i, label in enumerate(y_train) if label]\n",
    "pos = np.random.randint(len(indices_gatos))\n",
    "gato = features_train[indices_gatos[pos]]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(gato)\n",
    "plt.title('Ejemplo de gato')\n",
    "\n",
    "# Ejemplo de una imagen no gato\n",
    "indices_no_gatos = [i for i, label in enumerate(y_train) if not label]\n",
    "pos = np.random.randint(len(indices_no_gatos))\n",
    "gato = features_train[indices_no_gatos[pos]]\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(features_train[indices_no_gatos[pos]])\n",
    "plt.title('Ejemplo de no gato')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal de dos capas para clasificar imágenes de gatos\n",
    "\n",
    "**Ejercicio**: Completar la implementación de los métodos `red_dos_capas_clasifica_gatos()` utilizando los métodos *forward* y *backward* adecuados para dicha arquitectura. Como función de costo se utilizará la *entropía cruzada*. La red deberá tener la siguiente estructura: \n",
    "\n",
    "*AFIN -> RELU -> AFIN -> SIGMOIDE*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_dos_capas_clasifica_gatos(X, Y, dims_capas, num_iter = 1000, learning_rate = 1,  \n",
    "                                   mostrar_costo=False, semilla=100):\n",
    "    \"\"\"\n",
    "    Implementa una red neuronal de dos capas: Afin->Relu->Afin->Sigmoide.\n",
    "    \n",
    "    Entrada:\n",
    "        X: datos de entrada, de tamaño (N, d_0)\n",
    "        Y: etiquetas (1 para la clase positiva y 0 para la negativa), de tamaño (N,1)\n",
    "        dims_capas: dimensiones de las caoas(d_0, d_1, d_2)\n",
    "        num_iter: número de iteraciones del loop de optimización\n",
    "        learning_rate: learning rate utilizado para la actualización mediante descenso por gradiente\n",
    "        mostrar_costo: Si vale True, se muestra el costo cada 100 iteraciones \n",
    "        semilla: semilla utilizada para la generación de números aleatorios \n",
    "    Salida:\n",
    "        parametros: un diccionario de python que contiene W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(semilla)\n",
    "    gradientes = {} # se inicializa el diccionario que almacena los gradiantes\n",
    "    costos = []     # lista que almacena el costo\n",
    "    N = X.shape[0]  # número de muestras\n",
    "    d_0, d_1, d_2 = dims_capas  \n",
    "    \n",
    "    # Se inicializan los parámetros del diccionario llamando a una de las \n",
    "    # funciones previamente implementadas\n",
    "    parametros = inicializar_pesos(d_0, d_1, d_2, semilla=semilla)\n",
    "     \n",
    "    # Se obtienen W1, b1, W2 y b2 del diccionario de parámetros.\n",
    "    W1 = parametros[\"W1\"]\n",
    "    b1 = parametros[\"b1\"]\n",
    "    W2 = parametros[\"W2\"]\n",
    "    b2 = parametros[\"b2\"]\n",
    "    \n",
    "    # Loop (descenso por gradiente)\n",
    "\n",
    "    for i in range(0, num_iter):\n",
    "\n",
    "        ####################################################################################\n",
    "        ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "        \n",
    "        # Propagación hacia adelante: Afin -> ReLu -> Afin -> Sigmoide. \n",
    "        # Entradas: \"X, W1, b1\". Salidas: \"X1, cache1, X2, cache2\".\n",
    "\n",
    "        \n",
    "        # Se calcula el costo y se inicia la propagación hacia atrás\n",
    "\n",
    "        \n",
    "        # Propagación hacia atrás. \n",
    "        # Entradas: \"dX2, cache2, cache1\". Salidas: \"dX1, dW2, db2, dW1, db1, dX0 (no utilizado)\".\n",
    "        # print('dX2 shape:', dX2.shape)\n",
    "\n",
    "\n",
    "        # Se almacenan los gradientes recientemente calculados en el diccionario \n",
    "        \n",
    "        \n",
    "        # Se actualizan los parámetros\n",
    "        \n",
    "        \n",
    "        # Se obtienen los nuevos W1, b1, W2 y b2 del diccionario de parámetros.\n",
    "        \n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "\n",
    "        # Se muestra la evolución del costo cada 100 iteraciones\n",
    "        if mostrar_costo and i % 100 == 0:\n",
    "            print(\"Costo luego de iteracion {}: {}\".format(i, np.squeeze(costo)))\n",
    "            #print(W1,b1)\n",
    "        if mostrar_costo and i % 100 == 0:\n",
    "            costos.append(costo)\n",
    "         \n",
    "    # se muestra el costo\n",
    "    plt.plot(np.squeeze(costos))\n",
    "    plt.ylabel('costo')\n",
    "    plt.xlabel('iteraciones (sobre 100)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen las constantes que determinan la arquitectura de la red. En este caso se usarán como características los valores de los píxeles de la imagen. La capa oculta tendrá 7 nodos y habrá un solo nodo en la capa de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTES QUE DEFINEN EL MODELO ####\n",
    "d_0=features_train.shape[1]*features_train.shape[2]*features_train.shape[3]\n",
    "d_1 = 7\n",
    "d_2 = 1\n",
    "dims_capas = [d_0, d_1, d_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace un *reshape* de las imágenes de entrenamiento para que las entradas a la red sean vectores unidimensionales. Además se las normaliza para que los valores estén en el rango [0, 1] en vez del rango [0, 255] original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace el reshape de las características\n",
    "feat_train_flat = features_train.reshape(features_train.shape[0], -1)  \n",
    "\n",
    "# Se normalizan los datos para que las características queden en el rango [-0.5, 0.5]\n",
    "train_x = feat_train_flat/255. -0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar la siguiente celda y encontrar los parámetros del modelo. El costo debería decrecer con el paso de las iteraciones. Verificar que el  \"Costo luego de iteracion 0\" es aproximadamente 0.69, si no es así se recomienda para la ejecución con el cuadrado (⬛) de la barra superior del notebook y tratar de encontrar el error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_red_gatos = red_dos_capas_clasifica_gatos(train_x, y_train, dims_capas = [d_0, d_1, d_2], \n",
    "                                                     learning_rate=0.1, num_iter = 5000, mostrar_costo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la función de costo decreció por debajo de 0.003 al acercarse la iteración 5000 entonces la implementación es correcta y has podido entrenar la red neuronal. A continuación veremos qué tan bien funcionan los parámetros encontrados con el conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Completar la implementación del método `clasificar_gato()` para que dado un conjunto de imágenes de entrada y los parámetros de la red encontrados durante el entrenamiento devuelva si pertenece a la clase gato o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_gato(X, parametros):\n",
    "    \"\"\"\n",
    "    Esta función predice si las imágenes almacenadas en el vector X son gatos o no\n",
    "    \n",
    "    Entrada:\n",
    "        X: matriz de tamaño N x d_0 que contiene N imágenes almacenadas una por fila\n",
    "        parametros: parámetros óptimos encontrados al entrenar la red\n",
    "    \n",
    "    Salida:\n",
    "        p: predicciones realizadas por la red para las imágenes en X (1 si es gato, 0 si no)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Se obtienen W1, b1, W2 y b2 del diccionario de parámetros.\n",
    "    W1 = parametros[\"W1\"]\n",
    "    b1 = parametros[\"b1\"]\n",
    "    W2 = parametros[\"W2\"]\n",
    "    b2 = parametros[\"b2\"]\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    p = np.zeros((N,1))\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    # Se realiza la propagación hacia adelante de las imágenes de entrada\n",
    "    # ~ 2 lineas de código\n",
    "    \n",
    "    \n",
    "    # Se realiza la predicción \n",
    "    # ~ 1 línea de código\n",
    "\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar que la red entrenada hace un trabajo fantástico con el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_train = clasificar_gato(train_x, parametros_red_gatos)\n",
    "accuracy_train = str(np.mean((predicciones_train == y_train)))\n",
    "print(\"Porcentaje de acierto en entrenamiento: \"  + accuracy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cerca del 100% de acierto? ¡Bien hecho! Excelente trabajo. Ahora sólo resta evaluar con el conjunto reservado para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "####################################################################################\n",
    "\n",
    "# accuracy_test = \n",
    "\n",
    "####################################################################################\n",
    "###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "####################################################################################\n",
    "print(\"Porcentaje de acierto en test: \"  + accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Mucho mejor que tirar una moneda? Seguro que si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Comente cuáles son a su criterio las razones que explican el resultado obtenido y comente al menos un par de estrategias que de haberse implementado seguramente habrían redituado en un mejor desempeño con el conjunto de test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio2\"></a>\n",
    "# Ejercicio 2: Jugando con Tensorflow playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 1)** Ejecutar el [modelo parte 1](https://playground.tensorflow.org/#activation=linear&regularization=L2&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.01&regularizationRate=0&noise=35&networkShape=1&seed=0.68341&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&showTestData_hide=false&discretize_hide=false) y corroborar que no es capaz de separar correctamente los datos. Explicar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 2)** Aumentar el número de neuronas en capa oculta a dos. ¿Se pueden separar los datos? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 3)** Aumentar el número de neuronas en capa oculta a tres utilizando como función de activación ReLU. ¿Es este modelo adecuado para separar los datos? Ejecutar varias veces cambiando la inicialización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 4)** Probar ahora con la siguiente arquitectura:\n",
    "- Primera capa oculta con tres neuronas\n",
    "- Segunda capa oculta con tres neuronas\n",
    "- Tercera capa oculta con dos neuronas\n",
    "\n",
    "¿Este modelo se ajusta mejor a los datos? ¿Converge más rápido y con mayor asiduidad que el de la parte 3? A los efectos de este ejercicio consideraremos que el modelo converge si el error de test es menor a 0.177."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 5)** Utilizando sólamente $X_1$ y $X_2$ como características construir un modelo que separe adecuadamente los datos con [distribución en espiral](https://playground.tensorflow.org/#activation=linear&regularization=L2&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.01&regularizationRate=0&noise=0&networkShape=1&seed=0.63187&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&showTestData_hide=false&discretize_hide=false). Para ello puede variar libremente el número de capas ocultas y la cantidad de nodos por capa oculta. Indique además los valores elegidos para los siguientes parámetros y las razones que guiaron la elección:\n",
    "- learning rate\n",
    "- activación\n",
    "- tipo de regularización\n",
    "- factor de regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 6)** La extracción de características puede ser útil aún cuando se trabaja con clasificadores de gran capacidad expresiva como las redes neuronales. Utilizando las transformaciones de características a la entrada que considere convenientes, encontrar la arquitectura de red con menor cantidad de nodos que produzca un error con el conjunto de test menor a 0.1. *Sugerencia:*  guarde registro del momento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
