{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos de Aprendizaje Automático y Reconocimiento de Patrones\n",
    "***\n",
    "# Práctico 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "#%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "Los objetivos de este práctico son los siguientes:\n",
    "    \n",
    "- Implementar el método de **descenso por gradiente** para optimizar una función de costo. Identificar dificultades que pueden presentarse al utilizar el método de optimización y proponer estrategias que permitan mitigar las mismas.\n",
    "- Implementar **regresión lineal** utilizando **descenso por gradiente** y **descenso por gradiente estocástico**. Comparar la evolución de las funciones de costo y los pesos en ambos casos. Analizar la conveniencia de aplicar uno u otro método. \n",
    "- Formular el método de clasificación **regresión logística** e implementarlo. \n",
    "- Aplicar el método de regresión logística para **clasificar entre especies de la flor de Iris**.\n",
    "\n",
    "\n",
    "*** \n",
    "\n",
    "## Lista de ejercicios\n",
    "\n",
    "[Ejercicio 1](#Ejercicio1): descenso por gradiente de una función simple       \n",
    "[Ejercicio 2](#Ejercicio2): regresión lineal mediante descenso por gradiente     \n",
    "[Ejercicio 3](#Ejercicio3): regresión logística      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio1\"></a>\n",
    "## Ejercicio 1: Descenso por gradiente en una función \"simple\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se considera la función $f(x,y)=x^2+2y^2+2\\sin(2\\pi x)2\\sin(2\\pi y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej1 a)** Implementar descenso por gradiente para minimizar esta función. Considerar como condición inicial los valores $(x_0,y_0) = (0.1, 0.1)$. Utilizar como *learning rate* $\\eta=0.1$ y como número máximo de iteraciones 50. Comentar cómo evoluciona el costo en función del número de iteraciones. ¿Qué sucede si se modifica el *learning rate*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0, y0 = 0.1, 0.1 # por defecto 0.1, 0.1\n",
    "lr = 0.1 # por defecto 0.1\n",
    "nIter = 50\n",
    "F = np.zeros(nIter) # función de costo\n",
    "x, y = x0, y0\n",
    "n=0\n",
    "\n",
    "###################################################################\n",
    "############# EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO  ##############\n",
    "###################################################################\n",
    "for n in range(nIter):\n",
    "    grad_f = [2*x + 2*np.sin(2*np.pi*y)*np.cos(2*np.pi*x)*4*np.pi,\\\n",
    "              4*y + 2*np.sin(2*np.pi*x)*np.cos(2*np.pi*y)*4*np.pi]\n",
    "    x = x - lr*grad_f[0]\n",
    "    y = y - lr*grad_f[1]\n",
    "    \n",
    "    f = x**2 + 2*y**2 + 2*np.sin(2*np.pi*x)*2*np.sin(2*np.pi*y)\n",
    "    \n",
    "    F[n] = f\n",
    "\n",
    "###################################################################\n",
    "############# TERMINA ESPACIO PARA COMPLETAR CÓDIGO  ##############\n",
    "###################################################################\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(F)\n",
    "plt.title('Evolución del error')\n",
    "plt.xlabel('Numero de iteraciones')\n",
    "plt.ylabel('f')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**  \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej1 b)** Obtener las coordenadas del mínimo y su valor para las siguientes condiciones iniciales:\n",
    "\n",
    "| Condición inicial | ( x, y )* | F* |\n",
    "| ----------------- | ------ | ----- |\n",
    "| (0.1, 0.1)        |        |       |\n",
    "| (1, 1)            |        |       | \n",
    "| (-0.5, -0.5)      |        |       |\n",
    "| (-1, -1) |  |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 -2.7386853862894216\n",
      "22 -2.8956424123318008\n",
      "29 -1.677345739789003\n",
      "22 -2.8956424123318008\n"
     ]
    }
   ],
   "source": [
    "def calculate_min(x_0,y_0):\n",
    "    x0, y0 = x_0, y_0  # por defecto 0.1, 0.1\n",
    "    lr = 0.1 # por defecto 0.1\n",
    "    nIter = 50\n",
    "    F = np.zeros(nIter) # función de costo\n",
    "    x, y = x0, y0\n",
    "    n=0\n",
    "    \n",
    "    min_val = 10000000 # valor random alto\n",
    "    coord = [0,0]\n",
    "\n",
    "\n",
    "    for n in range(nIter):\n",
    "        grad_f = [2*x + 2*np.sin(2*np.pi*y)*np.cos(2*np.pi*x)*4*np.pi,\\\n",
    "                  4*y + 2*np.sin(2*np.pi*x)*np.cos(2*np.pi*y)*4*np.pi]\n",
    "        x = x - lr*grad_f[0]\n",
    "        y = y - lr*grad_f[1]\n",
    "\n",
    "        f = x**2 + 2*y**2 + 2*np.sin(2*np.pi*x)*2*np.sin(2*np.pi*y)\n",
    "        if f < min_val:\n",
    "            min_val = f\n",
    "            coord = n\n",
    "        F[n] = f\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(F)\n",
    "    plt.plot(coord, f,'ro')\n",
    "\n",
    "    plt.title('Evolución del error')\n",
    "    plt.xlabel('Numero de iteraciones')\n",
    "    plt.ylabel('f')\n",
    "    plt.tight_layout()\n",
    "    '''\n",
    "    return coord, min_val\n",
    "\n",
    "coord1, min_val1 = calculate_min(0.1, 0.1)\n",
    "coord2, min_val2 = calculate_min(1, 1)\n",
    "coord3, min_val3 = calculate_min(-0.5, -0.5)\n",
    "coord4, min_val4 = calculate_min(-1, -1)\n",
    "\n",
    "print(coord1, min_val1)\n",
    "print(coord2, min_val2)\n",
    "print(coord3, min_val3)\n",
    "print(coord4, min_val4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej1 c)** ¿Qué puede decir respecto a la función a optimizar y la técnica empleada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafica la función de costo para este caso\n",
    "# Pasar como parámetro el step de la grilla\n",
    "\n",
    "grid_step = 1\n",
    "xs = np.arange(-2, 2, grid_step)\n",
    "yes = np.arange(-2, 2, grid_step)\n",
    "xx, yy = np.meshgrid(xs, yes)\n",
    "z = xx**2 + 2*yy**2 + 2*np.sin(2*np.pi*xx) * 2*np.sin(2*np.pi*yy)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(xx,yy,z)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio2\"></a>\n",
    "## Ejercicio 2: Regresión lineal mediante descenso por gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se encontrarán los parámetros de una relación lineal entre dos variables unidimensionales utilizando descenso por gradiente y se lo comparará con el resultado obtenido mediante la solución cerrada vista en el práctico anterior. Para generar una relacion lineal rudiosa entre dos variables $x$ e $y$ se prové la función `generar_relacion_lineal_ruidosa(m, n, N, sigma)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_relacion_lineal_ruidosa(m, n, N, sigma):\n",
    "    '''\n",
    "    Entrada:\n",
    "        m: pendiente de la recta\n",
    "        n: término independiente\n",
    "        N: número de puntos a generar\n",
    "        sigma: desviación estándar del ruido\n",
    "    Salida:\n",
    "        x: N valores aleatorios en el rango [-1,1]\n",
    "        y: resultado de evaluar los N valores de x con el modelo ruidoso\n",
    "    '''\n",
    "    x = 2*np.random.rand(N)-1\n",
    "    senal = m * x + n \n",
    "    ruido = sigma * np.random.randn(N)\n",
    "    y = senal + ruido\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda genera dos vectores $\\mathbf{x}$, $\\mathbf{y}$ y muestra la relación generada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m=-2 ; n=0.5; N=100; sigma=0.1;\n",
    "x, y = generar_relacion_lineal_ruidosa(m,n,N,sigma)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x,y,c='b', s=2)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Relación lineal generada')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de costo que se minimiza mediante el método de mínimos cuadrados es:\n",
    "\n",
    "$$\n",
    "E_{in}(\\mathbf{w}) = \\frac{1}{2N}\\sum_{n=1}^N \\left( y_n - \\mathbf{w}^T \\mathbf{x}_n \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej2 a)** Encontrar los coeficientes del modelo utilizando la solución cerrada vista en el curso y verificar que los coeficientes obtenidos son similares a los utilizados para generar la señal. Recordar que en el modelo lineal el vector de características $\\mathbf{x}_n$ se encuentra expresado en coordenadas homogéneas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "############# EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO  ##############\n",
    "###################################################################\n",
    "X = np.ones((N,2))\n",
    "X[:,1] = x\n",
    "X_tras = np.transpose(X)\n",
    "\n",
    "w_ls = np.matmul(np.matmul(np.linalg.inv(np.matmul(X_tras, X)), X_tras),y)\n",
    "\n",
    "###################################################################\n",
    "############# TERMINA ESPACIO PARA COMPLETAR CÓDIGO  ##############\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej2 b)**  Calcular el gradiente de la función de costo respecto a los parámetros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**\n",
    "$$\n",
    "\\nabla E_{in}(w) = \\frac{1}{N} \\sum_{n=1}^N(w^Tx_n-y_n)x_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej2 c)** Implementar el método `minimos_cuadrados_mediante_descenso_por_gradiente()` y utilizarla para encontrar los coeficientes del modelo lineal. Notar que el resultado obtenido en la parte anterior utiliza todo el conjunto de entrenamiento para estimar el gradiente. Es por esta razón que a esta forma de calcular el gradiente se la suele llamar *Batch Gradient Descent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimos_cuadrados_mediante_descenso_por_gradiente(X, y, lr = 0.1, max_iter=1000, \n",
    "                                                      delta_w_minimo=1e-8):\n",
    "    '''\n",
    "    Entrada:\n",
    "        \n",
    "        X: matríz de tamaño Nx(d+1) donde cada fila representa una muestra\n",
    "        y: vector de tamaño N que contiene las etiquetas\n",
    "        lr: learning rate\n",
    "        max_iter: si el número de iteraciones alcanza a max_iter se detiene la optimización.\n",
    "        delta_w_minimo: si la norma L2 del vector diferencia entre vectores de pesos de dos \n",
    "                       iteraciones consecutivos es menor que delta_w_minimo se detiene la optimización\n",
    "                                  \n",
    "    Salida:\n",
    "        ws: lista de tamaño igual al número de iteraciones realizadas que contiene \n",
    "            los vectores de pesos encontrados durante el proceso de optimización \n",
    "    '''\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # se inicializan los pesos a valores aleatorios muy pequeños\n",
    "    w = 1e-6 * np.random.randn(X.shape[1])\n",
    "    ws = [w.copy()] # se inicializa la lista de pesos\n",
    "    delta_w = delta_w_minimo + 1 # de esta forma entra seguro al menos una vez\n",
    "    t=0 # contador de iteraciones\n",
    "    \n",
    "    while (t < max_iter and delta_w > delta_w_minimo):\n",
    "        \n",
    "        #################################################################################\n",
    "        #################  EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "        #################################################################################\n",
    "\n",
    "        grad_Ein = 1/N*np.sum\n",
    "\n",
    "        grad_f = [2*x + 2*np.sin(2*np.pi*y)*np.cos(2*np.pi*x)*4*np.pi,\\\n",
    "                  4*y + 2*np.sin(2*np.pi*x)*np.cos(2*np.pi*y)*4*np.pi]\n",
    "        x = x - lr*grad_f[0]\n",
    "        y = y - lr*grad_f[1]\n",
    "\n",
    "        f = x**2 + 2*y**2 + 2*np.sin(2*np.pi*x)*2*np.sin(2*np.pi*y)\n",
    "        F[n] = f\n",
    "        \n",
    "        #################################################################################\n",
    "        #################  TERMINA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "        #################################################################################\n",
    "   \n",
    "    print(\"minimos_cuadrados_mediante_descenso_por_gradiente() terminó en la iteración %d\" % t )\n",
    "    ws = np.array(ws)\n",
    "    \n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se encuentran los coeficientes del modelo utilizando batch gradient descent\n",
    "max_iter_BGD = 500 \n",
    "ws_bgd  = minimos_cuadrados_mediante_descenso_por_gradiente(Xh, y, max_iter = max_iter_BGD )\n",
    "w_bgd = ws_bgd[-1]\n",
    "print('El w encontrado utilizando batch gradient descent es: ', w_bgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descenso por gradiente estocástico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando el conjunto de datos de entrenamiento es muy grande, el descenso por gradiente recientemente implementado presenta la desventaja de ser muy lento. Es por eso que en la práctica es muy habitual utilizar una variante llamada *descenso por gradiente estocástico*. En la misma se calcula el gradiente utilizando una sola muestra. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej2 d)** Implementar `minimos_cuadrados_mediante_descenso_por_gradiente_estocastico()` y utilizarla para encontrar los coeficientes del modelo lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimos_cuadrados_mediante_descenso_por_gradiente_estocastico(X, y, lr = 0.1, \n",
    "                                                                max_epocas =1000, \n",
    "                                                                delta_w_minimo=1e-8):\n",
    "    '''\n",
    "    Entrada:\n",
    "        \n",
    "        X: matríz de tamaño Nx(d+1) donde cada fila representa una muestra\n",
    "        y: vector de tamaño N que contiene las etiquetas\n",
    "        lr: learning rate\n",
    "        max_epocas: si el número de épocas alcanza a max_epocas se detiene la optimización.\n",
    "                    Se llama una época a una pasada completa por el conjunto de \n",
    "                    entrenamiento.\n",
    "        delta_w_minimo: si la norma L2 del vector diferencia entre vectores de pesos de dos \n",
    "                        épocas consecutivos es menor que delta_w_minimo se detiene la optimización\n",
    "                                  \n",
    "    Salida:\n",
    "        ws: lista de tamaño igual al número de iteraciones realizadas que contiene los pesos de cada\n",
    "            iteración\n",
    "    '''\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # se inicializan los pesos a valores aleatorios muy pequeños\n",
    "    w = 1e-6 * np.random.randn(X.shape[1])\n",
    "    ws = [w.copy()]  # se inicializa la lista de pesos\n",
    "    delta_w = delta_w_minimo + 1 # de esta forma entra seguro al menos una vez\n",
    "    epoca_actual =0 # contador de épocas\n",
    "    \n",
    "    while (epoca_actual < max_epocas and delta_w > delta_w_minimo):\n",
    "        \n",
    "        #################################################################################\n",
    "        #################  EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "        #################################################################################\n",
    "\n",
    "        # se guarda el w de la época anterior\n",
    "        # w_= \n",
    "            \n",
    "        # se sortea el orden en que se visitan las muestras\n",
    "        # sugerencia: utilizar permutation() del paquete random\n",
    "        # indices = \n",
    "        for i in indices:\n",
    "            \n",
    "            # se calcula el gradiente \n",
    "            \n",
    "            \n",
    "            # se actualiza w\n",
    "\n",
    "            \n",
    "            # se almacena el nuevo w\n",
    "        \n",
    "        \n",
    "        # al terminar la época se calcula el delta_w\n",
    "        # delta_w = \n",
    "        \n",
    "        # se incrementa el valor de la época\n",
    "        \n",
    "        #################################################################################\n",
    "        #################  TERMINA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "        #################################################################################\n",
    "    \n",
    "    print(\"minimos_cuadrados_mediante_descenso_por_gradiente_estocastico() terminó en la época %d\" % epoca_actual )\n",
    "    ws = np.array(ws)\n",
    "    \n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define el número máximo de épocas en descenso por gradiente\n",
    "# estocástico de forma tal que el número de actualizaciones de los\n",
    "# pesos sea similar a la de batch gradient descent. Recordar que\n",
    "# en una época se realizan N actualizaciones de los pesos.\n",
    "max_epocas_SGD = np.max([max_iter_BGD//N, 1])\n",
    "\n",
    "ws_sgd  = minimos_cuadrados_mediante_descenso_por_gradiente_estocastico(Xh, y, \n",
    "                                                                        max_epocas=max_epocas_SGD)\n",
    "w_sgd=ws_sgd[-1]\n",
    "print('El w encontrado utilizando batch gradient descent es: ', w_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolución del costo en descenso por gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej2 e)** Implementar la función `evolucion_costo_descenso_por_gradiente()` y utilizarla para mostrar las curvas de error en ambos casos. ¿Qué similitudes y diferencias nota entre las curvas obtenidas por ambos métodos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolucion_costo_descenso_por_gradiente(X, y, ws):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: Matriz de Nx(d+1) que contiene los puntos a evaluar\n",
    "        y: vector con los valores de la variable independiente\n",
    "        ws: lista con los coeficientes del modelo obtenidos en cada actualización\n",
    "    Salida:\n",
    "        errores: lista con los errores (mean square errors) estimados en cada paso\n",
    "    '''\n",
    "    errores = []\n",
    "    \n",
    "    #################################################################################\n",
    "    #################  EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "    #################################################################################\n",
    "    \n",
    "        \n",
    "    #################################################################################\n",
    "    #################  TERMINA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "    #################################################################################\n",
    "    \n",
    "    return errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#################  EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "#################################################################################\n",
    "\n",
    "# errores_bgd = \n",
    "\n",
    "# errores_sgd = \n",
    "\n",
    "#################################################################################\n",
    "#################  TERMINA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "#################################################################################\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(errores_bgd)\n",
    "plt.title('Costo de descenso por gradiente (batch)')\n",
    "plt.xlabel('Número de actualizaciones')\n",
    "plt.subplot(122)\n",
    "plt.plot(errores_sgd)\n",
    "plt.title('Costo de descenso por gradiente estocástico')\n",
    "plt.xlabel('Número de actualizaciones')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolución de los pesos en descenso por gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda muestra como evolucionan los pesos durante la optimización. Correrla, mirar la animación y utilizarla para explicar el desempeño de ambos métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "cost_ax = fig.gca()\n",
    "cost_ax.plot(w_ls[1], w_ls[0], 'y*')\n",
    "\n",
    "ms = np.arange(-5., 5, 0.1)\n",
    "ns = np.arange(-5., 5, 0.1)\n",
    "mm, nn = np.meshgrid(ms, ns)\n",
    "costo = np.zeros_like(mm) \n",
    "for n in range(N):\n",
    "    costo += 1/N * (y[n] - (mm * x[n] + nn))**2\n",
    "\n",
    "cost_img = cost_ax.pcolor(mm, nn, costo)\n",
    "fig.colorbar(cost_img)\n",
    "\n",
    "def animar(i):\n",
    "    \n",
    "    cost_ax.cla()\n",
    "    cost_ax.plot(w_ls[1], w_ls[0], 'y*')\n",
    "    cost_ax.pcolor(mm, nn, costo)\n",
    "    cost_ax.plot(ws_bgd[:i,1], ws_bgd[:i,0], 'r--')\n",
    "    cost_ax.plot(ws_sgd[:i,1], ws_sgd[:i,0], 'g--')\n",
    "\n",
    "    cost_ax.set_xlim([-5, 5])\n",
    "    cost_ax.set_ylim([-5, 5])\n",
    "\n",
    "    cost_ax.set_xlabel(r'$m$')\n",
    "    cost_ax.set_ylabel(r'$n$')\n",
    "    cost_ax.set_title('Actualización %d' % i)\n",
    "\n",
    "    cost_ax.legend(('Solucion cerrada', 'BGD', 'SGD'), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "nIters = int(np.min([ws_bgd.shape[0],ws_sgd.shape[0]]))\n",
    "animacion = FuncAnimation(fig, animar, frames=nIters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej2 e)**  ¿Coinciden las soluciones de los distintos métodos? A modo de resumen comentar en qué  casos le parece conveniente utilizar cada uno de los métodos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio3\"></a>\n",
    "## Ejercicio 3:  Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un problema de dos clases, el modelo de regresión logística asume que la probabilidad a posteriori de pertenencia a la clase positiva puede ser escrita de la siguiente forma:\n",
    "\n",
    "$$\n",
    "P(y=1|\\mathbf{x}_n;\\mathbf{w})= \\theta \\left( \\mathbf{w}^T\\mathbf{x}_n \\right)= \\frac{1}{1+\\exp\\left(-\\left(\\mathbf{w}^T\\mathbf{x}_n\\right)\\right)}\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{x_n}=\\left( 1, x_{n1},x_{n2},...,x_{nd}\\right)$ es el n-ésimo vector de característcas expresado en coordenadas homogéneas y $d$ es el número de característcas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej3 a)** Mostrar que $P(y=y_n|\\mathbf{x}_n;\\mathbf{w}) = \\frac{1}{1+\\exp\\left(-\\left(y_n \\mathbf{w}^T\\mathbf{x}_n\\right)\\right)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej3 b)** Escribir la log verosimilitud $l(\\mathbf{y}| \\mathbf{X};\\mathbf{w})$ para este modelo en función de la función $\\theta(\\cdot)$ definida anteriormente. $\\mathbf{X}$ es una matriz de $N \\times (d+1)$ e $\\mathbf{y}$ es un vector que contiene las $N$ etiquetas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej3 c)** Mostrar que encontrar el $\\mathbf{w}$ que maximiza la verosimilitud es equivalente a encontrar el $\\mathbf{w}$ que minimiza la función de costo: \n",
    "\n",
    "$$\n",
    "E_{in}(\\mathbf{w}) = \\frac{1}{N}\\sum_{n=1}^N \\log \\left( 1 + \\exp \\left( -y_n \\mathbf{w}^T\\mathbf{x}_n \\right) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej3 d)** Mostrar que $$\\nabla E_{in}(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^{N} -y_n \\mathbf{x}_n \\theta  \\left( - y_n \\mathbf{w}^T\\mathbf{x_n} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**    \n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej3 e)** Implementar el método `regresion_logistica()` utilizando alguna de las variantes del método de descenso por gradiente para realizar la optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_logistica(X, y, lr = 0.1, max_iter=1000, delta_w_minimo=1e-7):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matríz de tamaño Nx(d+1) donde cada fila representa una muestra\n",
    "        y: vector de tamaño N que contiene las etiquetas\n",
    "        lr: learning rate\n",
    "        max_iter: si el número de iteraciones alcanza a max_iter se detiene la \n",
    "                  optimización.\n",
    "        delta_w_minimo: si la norma L2 del vector diferencia entre vectores de pesos de \n",
    "                        dos iteraciones consecutivos es menor que delta_w_minimo se \n",
    "                        detiene la optimización\n",
    "    Salida:\n",
    "        w: vector de pesos encontrado\n",
    "        error: vector de error de tamaño igual al número de iteraciones \n",
    "    '''     \n",
    "    \n",
    "    # se inicializan los pesos a valores aleatorios muy pequeños\n",
    "    w = 1e-6 * np.random.randn(X.shape[1])\n",
    "    error = []\n",
    "    \n",
    "    #################################################################################\n",
    "    #################  EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "    #################################################################################\n",
    "    \n",
    "        \n",
    "    #################################################################################\n",
    "    #################  TERMINA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "    #################################################################################\n",
    "    \n",
    "    \n",
    "    return w, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se aplicará el modelo de Regresión Logística para clasificar a la flor de Iris. La [base de datos Iris](https://en.wikipedia.org/wiki/Iris_flower_data_set) es una de las más conocidas en el área de aprendizaje automático por ser una de las primeras en ser introducidas a la comunidad. El problema original consiste en utilizar cuatro características de las flores (ancho y alto del pétalo y del sépalo) para separar en tres especies diferentes: Virgínica, Versicolor, Setosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizarán los datos disponibles en el [repositorio UCI](https://archive.ics.uci.edu/ml/datasets/iris). La siguiente celda levanta los datos y grafica las características dos a dos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = np.loadtxt('iris.data', delimiter=',', usecols=[0,1,2,3])\n",
    "labels = np.loadtxt('iris.data', delimiter=',', usecols=[4], dtype=str)\n",
    "features_names = ['sepal length','sepal width','petal length','petal width']\n",
    "labels_names = ['Virginica','Versicolor','Setosa']\n",
    "N,d = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_colores = {'Iris-versicolor': 'r', 'Iris-virginica':'b', 'Iris-setosa':'g' }\n",
    "colores = [mapa_colores[l] for l in labels]\n",
    "N,F = data.shape\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(F):\n",
    "    for j in range(F):\n",
    "        plt.subplot(4,4,1+i*F+j)\n",
    "        if i!=j:\n",
    "            plt.scatter(data[:,j],data[:,i],s=2, c=colores)\n",
    "            plt.xlabel(features_names[j])\n",
    "            plt.ylabel(features_names[i])\n",
    "        else:\n",
    "            plt.hist(data[:,i], bins=16, label='hist %s' % features_names[i])\n",
    "            plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se separarán las fores de Iris en dos categorías distintas. Implementar la función `preprocesar_iris()` que separa a las especies en dos, asignándoles la etiqueta +1 o -1 y dejándolas prontas para ser utilizadas por la función `regresion_logistica()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_iris(data, labels, clasesPositivas, clasesNegativas, features=[0,1,2,3]):\n",
    "    \n",
    "    '''\n",
    "    Entrada:\n",
    "        data: matríz de tamaño Nxd con las características de las N muestras\n",
    "        labels: vector que tiene las N etiquetas asignadas a las muestras\n",
    "        clasesPositivas: lista de etiquetas que van a asignarse a la clase positiva\n",
    "        clasesNegativas: lista de etiquetas que van a asignarse a la clase negativa\n",
    "        features: lista de características a utilizar. Por defecto se usan todas\n",
    "    Salida:\n",
    "        X: matríz de tamaño Nx(d+1) con las características a utilizar\n",
    "        y: vector de N etiquetas, valen +1 o -1\n",
    "    '''  \n",
    "    \n",
    "    # se transforma a coordenadas homogéneas\n",
    "    X = np.concatenate((np.ones((N,1)),data[:, features]),axis=1)\n",
    "    y = np.zeros(len(labels))\n",
    "    for clase in clasesPositivas:\n",
    "        labels_c = labels == clase\n",
    "        y[labels_c]=1\n",
    "    for clase in clasesNegativas:\n",
    "        labels_c = labels == clase\n",
    "        y[labels_c]=-1\n",
    "         \n",
    "    \n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de Iris-virgínica utilizando una característica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegir la característica que considere más discriminatoria y utilícela para separar la clase Iris-virgínica de las demás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clasesPositivas=['Iris-virginica']\n",
    "clasesNegativas=['Iris-setosa', 'Iris-versicolor']\n",
    "\n",
    "#################################################################################\n",
    "#################  EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "################################################################################# \n",
    "\n",
    "# Se elige la característica más discriminatoria y se obtienen los datos para\n",
    "# esa característica\n",
    "\n",
    "# features=[0] \n",
    "# Xiris1, y = \n",
    "\n",
    "# Se determinan los parámetros del modelo de regresión logística\n",
    "# w_iris1 = \n",
    "\n",
    "# Se calcula el umbral de decisión como el valor en que la probabilidad de pertenecer\n",
    "# a ambas clases es la misma. \n",
    "# umbral = ...\n",
    "\n",
    "#################################################################################\n",
    "#################  TERMINA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "################################################################################# \n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(error)\n",
    "plt.title('Evolución del costo en la regresión logística')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_umbral_clasificacion_iris1D(Xiris, y, umbral):\n",
    "    '''\n",
    "    Entrada: \n",
    "        Xiris: Matríz de Nx2 que contiene los features en coordenadas homogéneas\n",
    "        y: vector de etiquetas con valores 1 o -1\n",
    "        umbral: umbral de decisión enocontrado mediante regresión logística\n",
    "    '''\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(Xiris[y==-1, 1], y[y==-1], s=4,c='y',marker='x', label='negativas')\n",
    "    plt.scatter(Xiris[y==1,  1], y[y==1],  s=4,c='b',marker='x', label='positivas')\n",
    "    plt.axvline(umbral)\n",
    "    plt.title('El umbral de clasificación es %.02f' % umbral)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "mostrar_umbral_clasificacion_iris1D(Xiris1,y,umbral)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de otros métodos de clasificación, la clasificación mediante regresión logística brinda, para cada muestra, una probabilidad de pertencia a una determinada clase. Implementar el método `predecir_probabilidad_modelo_logistico()` y muestre las curvas de probabilidad de pertenencia a cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_probabilidad_modelo_logistico(X, w):\n",
    "    \n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matríz de tamaño Nx(d+1) que contiene las características de N muestras\n",
    "           en coordenadas homogéneas\n",
    "        w: vector de pesos estimado por modelo logístico\n",
    "    Salida:\n",
    "        probabilidades: matríz de tamaño Nx2 que en la primera columna almacena la probabilidad \n",
    "                        de pertenencia a la clase positiva y en la segunda la de pertenencia a \n",
    "                        la clase negativa\n",
    "    '''\n",
    "    \n",
    "    #################################################################################\n",
    "    #################  EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "    ################################################################################# \n",
    "    \n",
    " \n",
    "    \n",
    "    #################################################################################\n",
    "    #################  TERMINA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "    ################################################################################# \n",
    "    \n",
    "    return probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar la siguiente celda y verificar que el modelo encontrado es razonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra el modelo en función de la característica elegida\n",
    "x = np.linspace(0,Xiris1[:,1].max()+1)\n",
    "xh = np.hstack((np.ones( (len(x),1) ), x[:,np.newaxis] ))\n",
    "probs = predecir_probabilidad_modelo_logistico(xh, w_iris1)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(x, probs[:,0], c='b', label='probabilidad positiva')\n",
    "plt.plot(x, probs[:,1], c='y', label='probabilidad negativa')\n",
    "plt.scatter(Xiris1[y==-1 ,1], 0*y[y==-1], s=4,c='y',marker='x', label='negativas')\n",
    "plt.scatter(Xiris1[y==1,  1], y[y==1], s=4, c='b',marker='x', label='positivas')\n",
    "\n",
    "plt.axvline(umbral, label='umbral = %.02f' % umbral)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(features_names[features[0]])\n",
    "plt.ylabel('Probabilidad')\n",
    "plt.title('Probabilidad de pertenecer a la clase Iris-virgínica')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de Iris-virgínica utilizando dos característica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegir ahora las dos características que considere más discriminatorias y utilícelas para separar la clase Iris-virgínica de las demás. Comente como varía la solucón obtenida en función de los parámetros de optimización del modelo. Para visualizar el modelo obtenido puede ser útil la función `mostrar_lineas_de_nivel_modelo_logisitco()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_lineas_de_nivel_modelo_logisitco(X, w_rl):\n",
    "    '''\n",
    "    Este método muestra las líneas de isoprobabilidad en el caso de características 2D\n",
    "    Entrada:\n",
    "        X: matríz de tamaño Nx3 que en cada fila contiene una muestra (en coordenadas homogéneas)\n",
    "        w_rl: vector obtenido mediante regresión logística\n",
    "    '''\n",
    "    plt.figure()\n",
    "    x1_min = X[:,1].min(); x1_max = X[:,1].max()\n",
    "    x2_min = X[:,2].min(); x2_max = X[:,2].max()\n",
    "    xx = np.linspace(x1_min,x1_max)\n",
    "    yy = np.linspace(x2_min,x2_max)\n",
    "    XX, YY = np.meshgrid(xx, yy)\n",
    "    Zin=np.vstack( (np.ones(XX.size), XX.flatten(),YY.flatten()) ).T\n",
    "    Z = predecir_probabilidad_modelo_logistico(Zin,w_rl)\n",
    "    ZZ=np.reshape(Z[:,0],XX.shape)\n",
    "    plt.scatter(Xiris2[y==1,  1], Xiris2[y==1 ,2],  s=2, c='b',label='positivas')\n",
    "    plt.scatter(Xiris2[y==-1 ,1], Xiris2[y==-1 ,2], s=2, c='y',label='negativas')\n",
    "    cs = plt.contour(XX,YY,ZZ,[0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "    plt.clabel(cs, inline=1, fontsize=10)\n",
    "    plt.xlabel(features_names[features[0]])\n",
    "    plt.ylabel(features_names[features[1]])\n",
    "    plt.axis('equal')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#################  EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "################################################################################# \n",
    "\n",
    "# Se eligen las características que se consideran más discriminativas \n",
    "#features=[0, 1] \n",
    "\n",
    "\n",
    "# Se entrena el modelo y se muestran los resultados\n",
    "\n",
    "#################################################################################\n",
    "#################  TERMINA ESPACIO PARA COMPLETAR CÓDIGO ########################\n",
    "################################################################################# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
