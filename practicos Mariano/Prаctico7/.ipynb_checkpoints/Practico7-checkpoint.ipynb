{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> FUNDAMENTOS DE APRENDIZAJE AUTOMÁTICO <br> Y RECONOCIMIENTO DE PATRONES</center>\n",
    "## <center> Práctico 7, 2019 </center>      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las bibliotecas que se utilizarán\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "- Aplicar **k-vecinos** más cercanos para **clasificar** entre las 10 categorías de **dígitos**. Optimizar el parámetro *k* utilizando la biblioteca *scikit-learn*.\n",
    "- Estimar **densidades** de probabilidad mediante el método de **ventanas de Parzen** y aplicarlo a un problema de clasificación. \n",
    "- Implementar el algoritmo de **clustering k-means** y aplicarlo en de datos sintéticos. Analizar su funcionamiento.   \n",
    "- Realizar **agrupamiento de datos** mediante **mezcla de gaussianas**. Implementarlo utilizando el esquema **Expectation Maximization** para encontrar los parámetros. Comparar este agrupamiento con el de *k-means*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de ejercicios\n",
    "\n",
    "[Ejercicio 1](#Ejercicio1): *k-vecinos* más cercano       \n",
    "[Ejercicio 2](#Ejercicio2): ventanas de Parzen   \n",
    "[Ejercicio 3](#Ejercicio3): k-means   \n",
    "[Ejercicio 4](#Ejercicio4): mezcla de Gaussianas con EM   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones auxiliares (Ejecutar y seguir)\n",
    "def error_relativo(x, y):\n",
    "    ''' devuelve el error relativo'''\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: k-vecinos más cercanos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se utilizará *k-vecinos más cercanos* para clasificar la base de dígitos que viene con *scikit-learn*. La siguiente celda levanta los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La base de datos MNIST tiene 1797 dígitos\n"
     ]
    }
   ],
   "source": [
    "# se levantan los dígitos de la base MNIST \n",
    "mnist = load_digits()\n",
    "print('La base de datos MNIST tiene %d dígitos' % len(mnist.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte a)** Particionar aleatoriamente los datos utilizando el 70\\% de las muestras para entrenamiento, el 10\\% para validación y 20\\% para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(33)\n",
    "############################################################################################\n",
    "##########################  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  #########################\n",
    "############################################################################################\n",
    "\n",
    "# X_train, y_train =\n",
    "# X_val, y_val =\n",
    "# X_test, y_test =\n",
    "\n",
    "############################################################################################\n",
    "##########################  TERMINA ESPACIO PARA COMPLETAR CODIGO  #########################\n",
    "###########################################################################################\n",
    " \n",
    "# Se muestra el tamaño de los conjuntos generados\n",
    "print(\"El conjunto de entrenamiento tiene {} dígitos\".format(len(y_train)))\n",
    "print(\"El conjunto de validación tiene {} dígitos\".format(len(y_val)))\n",
    "print(\"El conjunto de test tiene {} dígitos\".format(len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte b)** Se utilizará la clase `KNeighborsClassifier` de *scikit-learn* para encontrar un clasificador mediante el método de vecino más cercano. Para encontrar el valor óptimo de *k* se usará el error con el conjunto de validación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se determina el rango de valores de k a probar \n",
    "rango_k = range(1, 20)\n",
    "# se inicializan la listas que guardarán E_in y E_val \n",
    "E_in = []\n",
    "E_val = []\n",
    " \n",
    "for k in rango_k:\n",
    "    \n",
    "    ####################################################################################\n",
    "    #################  EMPIEZA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "    ####################################################################################\n",
    "    \n",
    "    # se entrena el clasificador que usa k-vecinos \n",
    "\n",
    " \n",
    "    # se calculan y guardan E_in y E_val\n",
    "    \n",
    "    ####################################################################################\n",
    "    #################  TERMINA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "    ####################################################################################\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(rango_k, E_in,'*-', label='E_in')\n",
    "plt.plot(rango_k, E_val,'*-', label='E_val')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('error')\n",
    "plt.title('Error de clasificación utilizando k-vecinos más cercano')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte c)** ¿Cuál es el valor óptimo de *k* y el error con el conjunto de validación para dicho *k* ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#################  EMPIEZA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "####################################################################################\n",
    "\n",
    "# se encuentra el valor óptimo de k\n",
    "# k_opt =\n",
    "\n",
    "\n",
    "# error con el conjunto de validación\n",
    "# e_val_opt =\n",
    "\n",
    "####################################################################################\n",
    "#################  TERMINA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "####################################################################################\n",
    "\n",
    "print('El valor óptimo de k es %d, el error con el conjunto de validación es %f' % (k_opt, e_val_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte d)** Entrenar el clasificador óptimo y general las predicciones con el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#################  EMPIEZA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "####################################################################################\n",
    "\n",
    "# se entrena el clasificador óptimo\n",
    "#knn_clf =\n",
    "\n",
    "# se generan las predicciones de test\n",
    "#y_test_pred = \n",
    "\n",
    "####################################################################################\n",
    "#################  TERMINA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "####################################################################################\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte e)** Una forma alternativa de estimar los parámetros óptimos es mediante *validación cruzada* con *5 folds*. Utilice la clase `GridSearchCV` de *scikit-learn* para estimar los parámetros óptimos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#################  EMPIEZA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "####################################################################################\n",
    "\n",
    "# knn_cv =   # GridSearchCV para k-nn\n",
    "\n",
    "####################################################################################\n",
    "#################  TERMINA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "####################################################################################\n",
    "print('k optimo mediante cv = %f' % knn_cv.best_params_['n_neighbors'])\n",
    "print('accuracy = %f' % knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte f)** ¿Coinciden los valores óptimos encontrados? ¿Qué método le parece más adecuado para este problema en particular? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**  \n",
    "... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte g)** Dado el gran desempeño alcanzado por *k-nn* en la separación de dígitos, se merece una oportunidad en el problema de separación de sonidos urbanos del práctico anterior. Evalúelo y comente los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: ventanas de Parzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se utilizará la base de datos Iris para clasificación de flores disponible en *scikit learn*. Se considerará sólo el *largo* y el *ancho* del pétalo como características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "print(data['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte a)** Construya el vector de características y las etiquetas que se utilizarán en este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [2,3] # se eligen dos características\n",
    "\n",
    "####################################################################################\n",
    "#################  EMPIEZA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "####################################################################################\n",
    "\n",
    "# Vector de características en X\n",
    "# X =\n",
    "\n",
    "# se almacenan las etiquetas en el vector labels\n",
    "# labels =\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "#################  TERMINA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra la distribución de patrones para las tres clases presentes, cada\n",
    "una de ellas con un color diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X[:,0],X[:,1], c=labels)\n",
    "plt.xlabel(data['feature_names'][features[0]])\n",
    "plt.ylabel(data['feature_names'][features[1]])\n",
    "plt.title('Distribución de datos para la base iris')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desean estimar las densidades de cada clase utilizando el método de ventanas de Parzen con un *kernel* gaussiano de la forma: \n",
    "\n",
    "$$\n",
    "K(\\mathbf{x}, \\mathbf{z_i})=\\frac{1}{(2\\pi)^{d/2}\\vert \\Sigma \\vert^{1/2}} \n",
    "                               \\exp ^{\\left(-\\frac{1}{2}\\left( \\mathbf{x} - \\mathbf{z_i} \\right)^T \n",
    "                                        \\Sigma^{-1} \\left( \\mathbf{x} - \\mathbf{z_i} \\right) \\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte b)** Implementar el método `evaluar_kernel_gaussiano()`. Dicho método se utilizará para determinar la similitud entre la muestra a evaluar $\\mathbf{x}$ y una muestra de entrenamiento $\\mathbf{z_i}$ utilizando un *kernel gaussiano*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_kernel_gaussiano(x, mu, Sigma):\n",
    "    '''\n",
    "    Entrada:\n",
    "        x: vector a evaluar, de dimensión (d,1)\n",
    "        mu: media del núcleo gaussiano, de dimensión (d,1)\n",
    "        Sigma: covarianza del núcleo gaussiano, de dimensión (d,d)\n",
    "    Salida:\n",
    "        p: resultado de evaluar el kernel gaussiano\n",
    "    '''\n",
    "    ####################################################################################\n",
    "    #################  EMPIEZA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "    ####################################################################################\n",
    "    \n",
    "    # p =\n",
    "    \n",
    "    ####################################################################################\n",
    "    #################  EMPIEZA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "    ####################################################################################\n",
    "    \n",
    "    p = np.squeeze(p) # para asegurar que la salida es un escalar\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se testea evaluar_kernel_gaussiano() \n",
    "\n",
    "np.random.seed(33)\n",
    "d=5\n",
    "x_ = np.random.randn(d,1)\n",
    "mu_= np.random.randn(d,1)\n",
    "Sigma_ = np.random.randn(d,d)\n",
    "Sigma_ = Sigma_ @ Sigma_.T  # para que sea semidefinida positiva\n",
    "\n",
    "p = evaluar_kernel_gaussiano(x_, mu_, Sigma_)\n",
    "\n",
    "p_correcto = 2.29350214e-07\n",
    "# Se compara la salida con la nuestra. El error debería ser menor a e-9\n",
    "print('Testeando la función evaluar_kernel_gaussiano()')\n",
    "print('Diferencia: ', error_relativo(p, p_correcto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte c)** Implementar el método `estimar_densidad()` que evalúa, en un conjunto de puntos X, la densidad de probabilidad de pertenecer a una clase. La densidad se estima mediante el método de ventanas de Parzen utilizando los patrones de entrenamiento de dicha clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimar_densidad(X, Z, Sigma):\n",
    "    '''\n",
    "    Utiliza los patrones de entrenamiento Z pertenecientes a una misma clase, para \n",
    "    evaluar la densidad de probabilidad de dicha clase en los puntos pasados en X. \n",
    "    La densidad se estima mediante el método de ventanas de Parzen con núcleo gaussiano.   \n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nxd que contiene los puntos en donde se quiere \n",
    "           evaluar la densidad\n",
    "        Z: matriz de tamaño Mxd que contiene los puntos de entrenamiento\n",
    "        Sigma: matriz de covarianza del kernel gaussiano\n",
    "    Salida:\n",
    "        densidades: vector de tamaño N que almacena la densidad en los puntos evaluados\n",
    "    '''\n",
    "    \n",
    "    N, d = X.shape\n",
    "    M, d = Z.shape\n",
    "    \n",
    "    ####################################################################################\n",
    "    #################  EMPIEZA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "    ####################################################################################\n",
    "    \n",
    "    # densidades =  \n",
    "    \n",
    "    ####################################################################################\n",
    "    #################  TERMINA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "    ####################################################################################\n",
    "    \n",
    "    return densidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se testea estimar_densidad() \n",
    "np.random.seed(45)\n",
    "N=4; M=6\n",
    "d=3\n",
    "X_ = np.random.randn(N,d)\n",
    "Z_=  np.random.randn(M,d)\n",
    "Sigma_ = np.random.randn(d,d)\n",
    "Sigma_ = Sigma_ @ Sigma_.T  # para que sea semidefinida positiva\n",
    "\n",
    "densidades = estimar_densidad(X_, Z_, Sigma_)\n",
    "densidades_correctas = np.array([5.98438614e-02, 0, 4.83415432e-02, 1.86978536e-20])\n",
    "# Se compara la salida con la nuestra. El error debería ser menor a e-9\n",
    "print('Testeando la función evaluar_kernel_gaussiano()')\n",
    "print('Diferencia: ', error_relativo(densidades, densidades_correctas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte d)** Se estimará la densidad de cada una de las clases de la base Iris en una grilla de 50x50 puntos.\n",
    "Se considerará para la estimación de las densidades una matriz $\\Sigma$ de la forma $\\Sigma=r^2 \\Sigma_c$ siendo $\\Sigma_c$ la matriz de covarianza de los datos pretenecientes a la clase y $r$ el parámetro que controla el ancho del *núcleo gaussiano*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "r=1 # ancho del núcleo gaussiano\n",
    "\n",
    "for c in range(3):  # para cada una de las clases\n",
    "    \n",
    "    # se crea la grilla de 50x50 puntos que cubre el dominio de los puntos de la clase\n",
    "    x = np.linspace(X[labels==c,0].min(), X[labels==c,0].max())\n",
    "    y = np.linspace(X[labels==c,1].min(), X[labels==c,1].max())\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    \n",
    "    ####################################################################################\n",
    "    #################  EMPIEZA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "    ####################################################################################    \n",
    "    \n",
    "    # Se calculan las densidades en los puntos de la grilla. \n",
    "    # el arreglo 'densidades' tiene que tener las mismas dimensiones que xx e yy \n",
    "    \n",
    "    # densidades = \n",
    "    \n",
    "    ####################################################################################\n",
    "    #################  TERMINA ESPACIO PARA COMPLETAR CODIGO ###########################\n",
    "    ####################################################################################    \n",
    "\n",
    "    fig = plt.figure(num='surface', figsize=(5,5)) \n",
    "    ax = fig.gca(projection='3d')\n",
    "    surf = ax.plot_surface(xx, yy, densidades, rstride=1, cstride=1, \n",
    "                           cmap= plt.cm.coolwarm)\n",
    "\n",
    "    \n",
    "    plt.figure(num='contour', figsize=(5,5))\n",
    "    plt.scatter(X[labels==c,0],X[labels==c,1])\n",
    "    cs = plt.contour(xx, yy, densidades, levels=5)\n",
    "    plt.clabel(cs, inline=1, fontsize=10)\n",
    "\n",
    "fig = plt.figure(num='surface', figsize=(5,5)) \n",
    "plt.title('Densidades estimadas')\n",
    "plt.tight_layout()    \n",
    "plt.figure(num='contour', figsize=(5,5))\n",
    "plt.grid()\n",
    "plt.title('Líneas de nivel de la densidades estimadas')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte e)** Comente sobre la influencia del ancho de banda *r*  en las densidades estimadas y establezca un rango de valores razonable. Proponga un mecanismo para determinarlo automáticamente, esto es especialmente útil en aquellos casos en que no es posible visualizar las densidades resultantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**    \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio3\"></a>\n",
    "## Ejercicio 3: k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se verá k-means como técnica de agrupamiento de datos.\n",
    "\n",
    "**Parte a)** Completar la implementación del algoritmo k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def k_means(X, k, semilla=43):    \n",
    "    '''\n",
    "    Entrada:\n",
    "        X - arreglo de tamaño (N,d) que contiene los vectores de entrada\n",
    "        k - numero de clusters a encontrar\n",
    "        semilla - semilla que se usa para inicializar los centros.\n",
    "                  Elegir aleatoriamente k vectores de X\n",
    "    Salida:\n",
    "        centros: arreglo de tamaño (N,d) que contiene los centros de los \n",
    "                 clusters encontrados\n",
    "        etiquetas: vector de largo N que contiene a que cluster \n",
    "                   fue asignada la muestra  \n",
    "    '''\n",
    "    \n",
    "    np.random.seed(semilla)\n",
    "    \n",
    "    convergio = False  \n",
    "    n_iter = 0\n",
    "    ###########################################################################################\n",
    "    ##################    EMPIEZA ESPACIO PARA COMPLETAR CODIGO   #############################\n",
    "    ###########################################################################################\n",
    "    \n",
    "    # Se inicializan los centros de los clusters a muestras elegidas \n",
    "    # aleatoriamente \n",
    "\n",
    "    # centros = \n",
    "    \n",
    "    while not convergio:\n",
    "        \n",
    "        # 1. Se asignan las etiquetas al cluster cuyo centro es el más cercano. \n",
    "        # Se sugiere usar pairwise_distances del paquete metrics de sklearn \n",
    "        \n",
    "        # etiquetas = \n",
    "        \n",
    "\n",
    "        # 2. Se calculan los nuevos centros\n",
    "        # centros_nuevos = \n",
    "\n",
    "        # 3. Se evalúa la condición de convergencia (que los centros no cambien)\n",
    "        # convergio = \n",
    "\n",
    "        \n",
    "        # 4. Se actualiza la variable centros y se aumenta el número de iteración\n",
    "\n",
    "    \n",
    "    ###########################################################################################\n",
    "    ##################    TERMINA ESPACIO PARA COMPLETAR CODIGO   #############################\n",
    "    ###########################################################################################\n",
    "    print('El algoritmo finalizó en la iter %d' % n_iter)\n",
    "    \n",
    "    return centros, etiquetas   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte b)** Aplicarlo al conjunto de datos del archivo `data/data_4clusters.npz`. La variable `X` contiene los patrones a agrupar. En este caso el número de clusters es 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load('data/data_4clusters.npz')\n",
    "X = f['X']\n",
    "y = f['y']\n",
    "print(X.shape)\n",
    "\n",
    "###########################################################################################\n",
    "##################    EMPIEZA ESPACIO PARA COMPLETAR CODIGO   #############################\n",
    "###########################################################################################\n",
    "\n",
    "# centros, asignaciones = \n",
    "\n",
    "###########################################################################################\n",
    "##################    TERMINA ESPACIO PARA COMPLETAR CODIGO   #############################\n",
    "###########################################################################################\n",
    "\n",
    "dot_size = 50\n",
    "cmap = 'viridis'\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(X[:, 0], X[:, 1], c=asignaciones, s=dot_size, cmap=cmap)\n",
    "plt.title('Resultado de k-means', fontsize=18)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte c)** Verificar el correcto funcionamiento del algoritmo comparando los resultados obtenidos con los de la variable `y`. Para ello usar algunas de las [métricas](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation) disponibles en *scikit-learn*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_rand_score = \n",
    "# adj_mi_score = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte d)** Al variar el valor de la semilla que controla la inicialización ¿Siempre obtuvo resultados satisfactorios? En caso negativo, proponga un esquema para robustecer el método."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**    \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte e)** Utilice el algoritmo k-means para separar el conjunto de datos `data_4clusters_stretched` y comente los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=np.load('data/data_4clusters_stretched.npz')\n",
    "f.files\n",
    "X_st = f['X_st']\n",
    "y_st = f['y_st']\n",
    "\n",
    "###########################################################################################\n",
    "##################    EMPIEZA ESPACIO PARA COMPLETAR CODIGO   #############################\n",
    "###########################################################################################\n",
    "\n",
    "# centros_stretched, asignaciones_stretched = \n",
    "\n",
    "###########################################################################################\n",
    "##################    TERMINA ESPACIO PARA COMPLETAR CODIGO   #############################\n",
    "###########################################################################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(X_st[:, 0], X_st[:, 1], c=asignaciones_stretched, s=dot_size, cmap=cmap)\n",
    "plt.title('Resultado de k-means', fontsize=18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio4\"></a>\n",
    "## Ejercicio 4: EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "El objetivo de este ejercicio es implementar el esquema Expectation Maximization (EM) para encontrar los parámetros que maximizan la verosimilitud del modelo Mezcla de Gaussianas para un conjunto de datos $X$. Si se utilizan $\\textit{K}$ componentes en la mezcla, el modelo está dado por:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x_n|\\Theta})=\\sum_{j=1}^K w_j \\mathcal{N}\\left( \\mathbf{x_n} \\vert \\mathbf{\\mu_j},\\mathbf{\\Sigma_j} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementará una función que utiliza el esquema EM para encontrar los parámetros óptimos en el caso de Mezcla de Gaussianas. Dentro de la función el esquema sigue los siguientes pasos:\n",
    "\n",
    "1. Inicialización\n",
    "2. Loop donde se calculan:\n",
    "    - *Expectation Step* \n",
    "    - *Maximization Step*  \n",
    "    - log verosimilitud de los datos\n",
    "    - se evalúa condición de continuidad en el loop\n",
    "\n",
    "\n",
    "**Parte a)** Implementar la función `inicializar_mezcla()` que es la encargada de inicializar las medias $\\mathbf{\\mu_j}$, las covarianzas $\\mathbf{\\Sigma_j}$ y los coeficientes $\\mathbf{w}$ de la mezcla . Para facilitar la comparación con el algoritmo *k-means* del ejercicio anterior se sugiere inicializar los $\\mathbf{\\mu_j}$ a $\\textit{k}$ vectores de $X$ elegidos aleatoriamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializar_mezcla(X, k, semilla):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de tamaño (N,d) que contiene N muestras, una por fila\n",
    "        k: número de clusters a encontrar\n",
    "        semilla: hace repetible la inicialización aleatoria de parámetros\n",
    "    Salida:\n",
    "        w: vector de largo k que contiene los pesos de la mezcla. \n",
    "           Se deben inicializar a valores aleatorios cuya suma da 1 \n",
    "        mus: arreglo de tamaño (k,d) que contiene las k medias\n",
    "        sigmas: arreglo de tamaño (k,d,d) que contiene las matrices de covarianza de los clusters\n",
    "    '''\n",
    "    N, d = X.shape\n",
    "    \n",
    "    # la semilla controla la inicialización de los parámetros\n",
    "    np.random.seed(semilla)\n",
    "    \n",
    "    ######################################################################################\n",
    "    ##################    EMPIEZA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "    ######################################################################################\n",
    "\n",
    "    # se inicializan los mus eligiendo k vectores al azar\n",
    "    # mus = \n",
    "    \n",
    "    # los sigmas se inicializan a la identidad\n",
    "    # sigmas = \n",
    "    \n",
    "    # se inicializan el vector de pesos\n",
    "    # w =\n",
    "    \n",
    "    ########################################################################################\n",
    "    ##################    TERMINAA ESPACIO PARA COMPLETAR CODIGO   #########################\n",
    "    ########################################################################################\n",
    "    \n",
    "    return w, mus, sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se testea inicializar_mezcla() \n",
    "N=7; d=2; k=2\n",
    "X_ = np.random.randn(N,d)\n",
    "semilla = 43\n",
    "w, mus, sigmas = inicializar_mezcla(X, k, semilla)\n",
    "\n",
    "sigmas_correctos = np.array([[[1., 0.], [0., 1.]], [[1., 0.], [0., 1.]]])\n",
    "\n",
    "print('Testeando la función inicializar_mezcla()')\n",
    "assert np.sum(w)==1, 'La suma de los w debe dar 1'\n",
    "assert np.min(w)>=0, 'Los w deben ser positivos o cero'\n",
    "assert mus.shape == (k,d), 'El tamaño de la matriz de mus no es correcto'\n",
    "for j in range(k):\n",
    "    assert np.allclose(sigmas[j], np.eye(len(sigmas[j]))), 'Los sigmas deben inicializarse a la identidad'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte b)** Implementar `expectation_step`. Se calcula la probabilidad de que la *n-ésima* muestra haya sido generada por la componente *j-ésima* de la mezcla. Para ello se utilizan los parámetros actuales   \n",
    "\n",
    "$$\n",
    "\\gamma_{nj} = \\frac{w_j \\mathcal{N}\\left( \\mathbf{x_n} \\vert \\mathbf{\\mu_j},\\mathbf{\\Sigma_j} \\right)}{\\sum_{l=1}^{L} w_l \\mathcal{N}\\left( \\mathbf{x_n} \\vert \\mathbf{\\mu_l},\\mathbf{\\Sigma_l} \\right)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_step(X, w, mus, sigmas):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nxd con las muestras a evaluar\n",
    "        w: vector de largo k que contiene los pesos de la mezcla. \n",
    "        mus: arreglo de tamaño (k,d) que contiene las k medias\n",
    "        sigmas: arreglo de tamaño (k,d,d) que contiene las matrices de covarianza de los clusters\n",
    "    Salida:\n",
    "        gammas: matriz de tamaño Nxk con las probabilidades de pertenencia a cada cluster\n",
    "    '''\n",
    "    \n",
    "\n",
    "    ######################################################################################\n",
    "    ##################    EMPIEZA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "    ######################################################################################\n",
    "    \n",
    "    # gammas = \n",
    "    \n",
    "    ######################################################################################\n",
    "    ##################    TERMINA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "    ######################################################################################\n",
    "    return gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se testea expectation_step() \n",
    "np.random.seed(3)\n",
    "N=2; d=3; k=2\n",
    "X_ = np.random.randn(N,d)\n",
    "w_ = np.random.rand(k)\n",
    "w_ = w_ / np.sum(w_)\n",
    "mus_= np.random.randn(k,d)\n",
    "sigmas_= np.random.randn(k,d,d)\n",
    "for j in range(k):\n",
    "    sigmas_[j]= sigmas_[j] @ sigmas_[j].T\n",
    "\n",
    "gammas = expectation_step(X_, w_, mus_, sigmas_)\n",
    "print(gammas)\n",
    "gammas_correctos = np.array([[1.34208238e-04, 9.99865792e-01],\n",
    "                             [9.99999062e-01, 9.38144350e-07]])\n",
    "\n",
    "# Se compara la salida con la nuestra. Los errores deberían ser del orden de e-9 o menos\n",
    "print('Testeando la función expectation_step()')\n",
    "print('Diferencias en gammas: ', error_relativo(gammas, gammas_correctos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte c)** Implementar `maximization_step()`. Se encuentran los parámetros óptimos utilizando la distribución de $\\gamma_{nj}$ actual\n",
    "\n",
    "\\begin{align*}\n",
    "&N_j                       = \\sum_{n=1}^{N}\\gamma_{nj} \\\\\n",
    "&\\mathbf{\\mu_j^{new}}      = \\frac{1}{N_j}\\sum_{n=1}^{N}\\gamma_{nj}\\mathbf{x_n}  \\\\\n",
    "&\\mathbf{\\Sigma_j^{new}}   = \\frac{1}{N_j}\\sum_{n=1}^{N}\\gamma_{nj}\\left(\\mathbf{x_n}-\\mathbf{\\mu_j}\\right)\\left(\\mathbf{x_n}-\\mathbf{\\mu_j}\\right)^T  \\\\\n",
    "&w_j^{new}               = \\frac{N_j}{N} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximization_step(X, gammas):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nxd con las muestras a evaluar\n",
    "        gammas: matriz de tamaño Nxk con las probabilidades de pertenencia a cada cluster\n",
    "    Salida:\n",
    "        w: vector de pesos de la mezcla\n",
    "        mus: arreglo de (k,d) con las medias de los clusters\n",
    "        sigmas: arreglo de (k,d,d) que contiene las matrices de covarianza de los clusters        \n",
    "    '''\n",
    "    \n",
    "    ######################################################################################\n",
    "    ##################    EMPIEZA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "    ######################################################################################    \n",
    "    \n",
    "    # w =\n",
    "\n",
    "    # mus =\n",
    "\n",
    "    # sigmas =\n",
    "        \n",
    "    ######################################################################################\n",
    "    ##################    TERMINA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "    ######################################################################################\n",
    "        \n",
    "        \n",
    "    return w, mus, sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se testea maximization_step() \n",
    "np.random.seed(84)\n",
    "N=5; d=2; k=2\n",
    "X_ = np.random.randn(N,d)\n",
    "gammas_ = np.random.randn(N,k)\n",
    "w, mus, sigmas = maximization_step(X_, gammas_)\n",
    "\n",
    "w_correcto = np.array([-0.50647492,  0.60709566])\n",
    "mus_correctos = np.array([[ 0.03196345, -1.57011573], [-0.12383003, -0.67268656]])\n",
    "sigmas_correctos = np.array([[[ 0.58728466, -0.36449661],[-0.36449661,  0.4157087 ]],\n",
    "                             [[ 0.21543145, -0.16303434],[-0.16303434,  0.30495924]]])\n",
    "\n",
    "# Se compara la salida con la nuestra. Los errores deberían ser del orden de e-8 o menos\n",
    "print('Testeando la función inicializar_mezcla()')\n",
    "print('Diferencias en w: ', error_relativo(w, w_correcto))\n",
    "print('Diferencias en mus: ', error_relativo(mus, mus_correctos))\n",
    "print('Diferencias en sigmas: ', error_relativo(sigmas, sigmas_correctos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte e)** Implemente el método `log_verosimilitud()` que evalúa la log-verosimilitud de los datos con el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "def log_verosimilitud(X, w, mus, sigmas):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nxd que contiene las muestras\n",
    "        w: vector de tamaño k que contiene los pesos actuales\n",
    "        mus: matriz de tamaño (k,d) que contiene las medias, una por fila\n",
    "        sigmas: arreglo de tamaño (k,d,d) que contiene las matrices de covarianza\n",
    "     Salida:\n",
    "        log_ver: log verosimilitud de las muestras con el modelo (escalar)\n",
    "    '''\n",
    "    \n",
    "    ######################################################################################\n",
    "    ##################    EMPIEZA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "    ######################################################################################\n",
    "        \n",
    "    # log_ver =   \n",
    "    \n",
    "    ######################################################################################\n",
    "    ##################    TERMINA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "    ######################################################################################\n",
    "    return log_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se testea log_verosimilitud() \n",
    "np.random.seed(22)\n",
    "N=3; d=3; k=2\n",
    "X_ = np.random.randn(N,d)\n",
    "w_ = np.random.rand(k)\n",
    "w_ = w_ / np.sum(w_)\n",
    "mus_= np.random.randn(k,d)\n",
    "sigmas_= np.random.randn(k,d,d)\n",
    "for j in range(k):\n",
    "    sigmas_[j]= sigmas_[j] @ sigmas_[j].T\n",
    "\n",
    "log_ver = log_verosimilitud(X_, w_, mus_, sigmas_)\n",
    "print(log_ver)\n",
    "log_ver_correcto = -28.48357133785\n",
    "\n",
    "# Se compara la salida con la nuestra. El error debería ser del orden de e-9 o menos\n",
    "print('Testeando la función log_verosimilitud()')\n",
    "print('Diferencias en log_ver: ', error_relativo(log_ver, log_ver_correcto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte f)** Complete la implementación de `gmm_EM`. Para ello utilice las implementaciones de las partes anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_EM(X, k, tol=0.01, max_iter=100, semilla = 2):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nxd que contiene N muestras, una por fila\n",
    "        k: número de clusters a encontrar\n",
    "        tol: si la log verosimilitud en el paso actual no mejora al menos tol\n",
    "             respecto a la del paso anterior se termina la optimización \n",
    "        max_iter: máximo número de iteraciones en la optimización\n",
    "        semilla: semilla a utilizar en la inicialización de las gaussianas\n",
    "    Salida:\n",
    "        log_ver: lista que almacena las log-verosimilitudes calculadas durante la optimización\n",
    "        gammas: matriz de tamaño Nxk con las probabilidades de pertenencia a cada cluster\n",
    "        w: vector de tamaño k que contiene los pesos estimados\n",
    "        mus: matriz de tamaño (k,d) que contiene las medias, una por fila\n",
    "        sigmas: arreglo de tamaño (k,d,d) que contiene las matrices de covarianza\n",
    "    '''\n",
    "    N, d = X.shape\n",
    "    \n",
    "    w, mus, sigmas = inicializar_mezcla(X, k, semilla)\n",
    "\n",
    "    log_ver_previa = -np.infty ; \n",
    "    log_ver=[] # lista que almacena las log-verosimilitudes durante la optimización\n",
    "    \n",
    "    termino = False\n",
    "    n_iter = 0\n",
    "    while not termino:\n",
    "        \n",
    "       ######################################################################################\n",
    "       ##################    EMPIEZA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "       ######################################################################################        \n",
    "        \n",
    "        # E-step   \n",
    "      \n",
    "\n",
    "        # M-step        \n",
    "    \n",
    " \n",
    "        # se actualiza la log verosimilitud\n",
    "        # log_ver_actual =\n",
    "        \n",
    "        # se evalúa condición de terminación (dos condiciones)\n",
    "        # termino =  \n",
    "        \n",
    "        ######################################################################################\n",
    "        ##################    EMPIEZA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "        ######################################################################################\n",
    "        \n",
    "        log_ver.append(log_ver_actual)\n",
    "        log_ver_previa = log_ver_actual\n",
    "\n",
    "        n_iter += 1\n",
    "    \n",
    "        print('Iteración %d, log verosimilitud = %f ' % (n_iter, log_ver_actual))\n",
    "        \n",
    "    return log_ver, gammas, w, mus, sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación utilizando data_4clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda evalúa la implementación realizada. Verifique que la log verosimilitud es monótona creciente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=np.load('data/data_4clusters_stretched.npz')\n",
    "f.files\n",
    "X_st = f['X_st']\n",
    "y_st = f['y_st']\n",
    "#log_vero, gammas, w, mus, sigmas = gmm_EM(X_st, k=4, max_iter=100, tol=0.001)\n",
    "log_vero, gammas, w, mus, sigmas = gmm_EM(X_st, k=4, max_iter=100, tol=0.001, semilla=22)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(log_vero)\n",
    "plt.title('Log verosimilitud')\n",
    "plt.xlabel('iteraciones')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte g)** Realice la asignación de clusters y compare los resultados con los obtenidos con el algoritmo *k-means*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "##################    EMPIEZA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "###################################################################################### \n",
    "# vector de tamaño N que almacena los clusters asignados a cada muestra \n",
    "# asignaciones_gmm =      \n",
    "\n",
    "######################################################################################\n",
    "##################    TERMINA ESPACIO PARA COMPLETAR CODIGO   ########################\n",
    "###################################################################################### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestran con el mismo color los puntos pertenecientes al mismo cluster \n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(X_st[:, 0], X_st[:, 1], c=asignaciones_gmm, s=dot_size, cmap=cmap)\n",
    "plt.title('resultado EM', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
