{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> FUNDAMENTOS DE APRENDIZAJE AUTOMÁTICO <br> Y RECONOCIMIENTO DE PATRONES</center>\n",
    "## <center> 2do parcial, 2019</center>           \n",
    "\n",
    "La duración del parcial es de 3 horas. El parcial consta de 3 ejercicios, cuya suma total es de 100 puntos. El parcial es sin material y no está permitido acceder a Internet. Ante cualquier duda comuníquese con los docentes. \n",
    "\n",
    "Este notebook corresponde al ejercicio 1. Hay un notebook por ejercicio planteado.\n",
    "\n",
    "* [Ejercicio 1 - Redes Neuronales](#Ejercicio1) (35 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las bibliotecas que se utilizarán\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio1\"></a>\n",
    "## Ejercicio 1: Completar la implementación de una red neuronal de dos capas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones auxiliares (Ejecutar y seguir)\n",
    "def error_relativo(x, y):\n",
    "    ''' devuelve el error relativo'''\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def calcular_gradiente_numerico_array(f, x, df, h=1e-5):\n",
    "    '''\n",
    "    Evalúa el gradiente numérico para una función que acepta un arreglo numpy y\n",
    "    devuelve un arreglo numpy.\n",
    "    '''\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h\n",
    "        pos = f(x).copy()\n",
    "        x[ix] = oldval - h\n",
    "        neg = f(x).copy()\n",
    "        x[ix] = oldval\n",
    "\n",
    "        grad[ix] = np.sum((pos - neg) * df) / (2 * h)\n",
    "        it.iternext()\n",
    "    return grad\n",
    "\n",
    "\n",
    "def calcular_gradiente_numerico(f, x, verbose=True, h=0.00001):\n",
    "    '''\n",
    "    Evalúa el gradiente numérico de f en x\n",
    "    - f es una función que recibe un solo argumente\n",
    "    - x es el punto (numpy array) en que se evalúa el gradiente\n",
    "    '''\n",
    "    \n",
    "    # se inicializa el gradiente \n",
    "    grad = np.zeros_like(x)\n",
    "    # se define un iterador sobre todos los elementos de x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # se evalúa la función en x+h\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h # se suma h al valor original de x\n",
    "        fxph = f(x) # se evalúa f(x + h)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x) # se evalúa f(x - h)\n",
    "        x[ix] = oldval # se restaura el valor original de x\n",
    "\n",
    "        # se calcula la derivada parcial con la fórmula centrada\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h) \n",
    "        if verbose:\n",
    "            print(ix, grad[ix])\n",
    "        it.iternext() # step to next dimension\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se implementarán algunos de los bloques constitutivos de una red neuronal de **tres capas**. El diagrama muestra el diagrama de bloques para la red de dos capas implementada en el práctico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/diagrama_de_bloques.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se describen los bloques:\n",
    "- **Inicializar parámetros:** Inicializa los parámentros de la red. A los pesos de la capa $l$ de la red les llamaremos $W_l$, $b_l$ con $l=1,2,3$. \n",
    "- **Propagación hacia adelante:** La *propagación hacia adelante*  o *forward propagation* consiste en estimar la salida de la red a partir de la entrada. Cada nodo o capa de la red tiene un método *forward* asociado. Se proveen las implementaciones de los métodos forward asociados a los siguientes bloques:\n",
    "        - Afin\n",
    "        - Activación \n",
    "        - Afin --> Activación\n",
    "        \n",
    "- **Loss:** Calcula el valor de la función de costo a optimizar. Se implementarán dos funciones de costo:\n",
    "        - Entropía cruzada\n",
    "        - Entropía cruzada regularizada\n",
    "- **Propagación hacia atrás:** Durante la *propagación hacia atrás* o *backpropagation* se calculan los gradientes necesarios para actualizar los parámetros de la red. Se implementarán métodos *backward* para los siguientes bloques:\n",
    "        - Afin\n",
    "        - Activación \n",
    "        - Afin --> Activación\n",
    "- **Update:** Es el boque encargado de actualizar los parámetros. Para ello utiliza los gradientes calculados durante la *propagación hacia atrás* y un método de optimización. Se utilizará *descenso por gradiente* como método de optimización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Bloque de Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementará el bloque de inicialización para el caso de una red neuronal de **tres capas** con la siguiente estructura:    \n",
    "  Afin --> Activación 1 --> Afin --> Activacion 2 --> Afin --> Activación 3       \n",
    "\n",
    "### Parte a) \n",
    "Completar la implementación de `inicializar_pesos()`. Los pesos $W_l$ serán inicializados en valores aleatorios con distribución gaussiana de desviación estandar $\\sigma_l=1/\\sqrt{d_{l-1}}$, siendo $d_{l-1}$ el número de nodos de la capa $l-1$. Por ejemplo, para la primera capa $l=1$, la cantidad de nodos $d_{l-1}=d_0$ corresponde a la dimensión del vector de características. Los pesos correspondientes a términos de *bias* se inicializarán a cero. \n",
    "\n",
    "**Nota:** No necesario realizar una implementación genérica. Alcanza con que funcione para una red de tres capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializar_pesos(dims, semilla=1):\n",
    "    \"\"\"\n",
    "    Entrada:\n",
    "        dims: lista que contiene el número de nodos de cada una de las capas. El primer elemento\n",
    "              corresponde al tamaño del vector de características y el último a la cantidad de \n",
    "              nodos en la última capa oculta.\n",
    "        semilla: semilla a utilizar para generar los valores aleatorios\n",
    "    \n",
    "    Salida:\n",
    "        parametros: diccionario de python que contiene los parámetros inicializados \n",
    "                    parametros['W' + str(l)] = ... \n",
    "                    parametros['b' + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(semilla)\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    # Sugerencia: puede ser útil utilizar np.random.randn() y ajustar la desviación estándar\n",
    "    \n",
    "    W1 = np.random.randn(dims[0],dims[1])*(1/np.sqrt(dims[0]))\n",
    "    b1 = np.zeros(dims[1])\n",
    "    \n",
    "    W2 = np.random.randn(dims[1],dims[2])*(1/np.sqrt(dims[1]))\n",
    "    b2 = np.zeros(dims[2])\n",
    "    \n",
    "    W3 = np.random.randn(dims[2],dims[3])*(1/np.sqrt(dims[2]))\n",
    "    b3 = np.zeros(dims[3])\n",
    "    \n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "   \n",
    "    # Se genera el diccionario con los valores inicializados\n",
    "    parametros = {'W1': W1,\n",
    "                  'b1': b1,\n",
    "                  'W2': W2,\n",
    "                  'b2': b2,\n",
    "                  'W3': W3,\n",
    "                  'b3': b3}\n",
    "    \n",
    "    return parametros    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testeando la incialización aleatoria:\n",
      "Diferencia en W1:  1.1841719957328453e-08\n",
      "Diferencia en b1:  0.0\n",
      "Diferencia en W2:  8.297892749808612e-08\n",
      "Diferencia en b2:  0.0\n",
      "Diferencia en W3:  1.3902130737322008e-08\n",
      "Diferencia en b3:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Se testea la inicialización con pesos aleatorios\n",
    "dims = [3,6,3,1]\n",
    "parametros = inicializar_pesos(dims)\n",
    "\n",
    "W1_correcto = np.array([[ 0.93781623, -0.35319773, -0.3049401 , -0.61947872,  0.49964333, -1.32879399],\n",
    "                       [ 1.00736754, -0.43948301,  0.18419731, -0.14397405,  0.84414841, -1.18942279],\n",
    "                         [-0.18614766, -0.22173389,  0.65458209, -0.63502252, -0.09955147, -0.50683179]])\n",
    "b1_correcto = np.array([0., 0., 0., 0., 0., 0.])\n",
    "W2_correcto = np.array([[ 0.01723369,  0.23793331, -0.4493259 ],[ 0.4673315 ,  0.36807287,  0.20514245],\n",
    "                       [ 0.3677729 , -0.27913073, -0.05016972], [-0.38202627, -0.10936485,  0.21651671],\n",
    "                       [-0.28236932, -0.16197395, -0.28053708], [-0.34505376, -0.27403509, -0.0051703 ]])\n",
    "b2_correcto = np.array([0., 0., 0.])  \n",
    "W3_correcto = np.array([[-0.64507943],\n",
    "       [ 0.13533997],\n",
    "       [ 0.95828723]])\n",
    "b3_correcto = np.array([0.])\n",
    "\n",
    "# Se compara la salida con la nuestra. El error debería ser e-7 o menos.\n",
    "print('Testeando la incialización aleatoria:')\n",
    "print('Diferencia en W1: ', error_relativo(parametros['W1'], W1_correcto))\n",
    "print('Diferencia en b1: ', error_relativo(parametros['b1'], b1_correcto))\n",
    "print('Diferencia en W2: ', error_relativo(parametros['W2'], W2_correcto))\n",
    "print('Diferencia en b2: ', error_relativo(parametros['b2'], b2_correcto))\n",
    "print('Diferencia en W3: ', error_relativo(parametros['W3'], W3_correcto))\n",
    "print('Diferencia en b3: ', error_relativo(parametros['b3'], b3_correcto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Bloques Forward\n",
    "\n",
    "Se proveen las implementaciones de los métodos *forward* de los siguientes bloques: \n",
    "\n",
    "- Bloque Afin  \n",
    "- Bloque Activación donde la activación puede ser ReLU, Sigmoide\n",
    "- Bloque Afin -> Activación  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Forward Afin\n",
    "\n",
    "La señal de entrada a la activación de la capa $\\textit{l}$ puede escribirse como:\n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(l)}=\\left( W^{(l)} \\right)^T \\mathbf{x}^{(l-1)}+ \\mathbf{b}^{(l)}   \\tag{1}\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{s}^{(l)}$ y $\\mathbf{b}^{(l)}$ son vectores de tamaño $d^{(l)}$, $\\mathbf{x}^{(l-1)}$  es un vector de tamaño $d^{(l-1)}$ y $W^{(l)}$ es una matriz de tamaño $d^{(l-1)} \\times d^{(l)}$.\n",
    "\n",
    "La ecuación (1) es válida cuando la entrada a la capa es un único vector $\\mathbf{x}^{(l-1)}$. En la práctica es más habitual procesar un $\\textit{batch}$ de vectores de entrada a la vez, por lo tanto es deseable contar con una expresión que genere la salida para todos los vectores de entrada a la vez. Al evitar la utilización de un bloque $\\textit{for}$ que itere por cada una de las muestras del $\\textit{batch}$ se mejora la eficiencia de la implementación.   \n",
    "\n",
    "\n",
    "La versión de la ecuación (1) que actúa sobre un conjunto de muestras a la vez es la siguiente:\n",
    "\n",
    "$$\n",
    "S^{(l)} = X^{(l-1)}W^{(l)} +b^{(l)}\\tag{2}\n",
    "$$\n",
    "\n",
    "donde $X^{[0]} = X$, siendo X una matriz que contiene un vector de características en cada fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_forward(X, W, b):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia adelante en una capa afin.\n",
    "\n",
    "    Entrada:\n",
    "        X: matriz de tamaño (N, dim capa anterior) que en cada fila contiene un vector de\n",
    "           activaciones de la capa anterior (o datos de entrada)\n",
    "        W: matriz de pesos de tamaño (dim de capa anterior, dim de capa actual) \n",
    "        b: vector de bias de tamaño (dim de la capa actual,)\n",
    "\n",
    "    Salida:\n",
    "        S: matriz de tamaño (N, dim de capa actual) que contiene\n",
    "           los scores o señal de entrada a la activación  \n",
    "        cache: (X, W, b) tupla que contiene X, W y b. \n",
    "               Son almacenados para calcular el paso backward eficientemente\n",
    "    \"\"\"\n",
    "\n",
    "    S = np.dot(X, W) + b\n",
    "    \n",
    "    assert(S.shape == (X.shape[0], W.shape[1] ))\n",
    "    cache = (X, W, b)\n",
    "    \n",
    "    return S, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Funciones de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proveen las implementaciones de las siguientes funciones de activación:\n",
    "\n",
    "- **Sigmoide**: $\\sigma(S) = \\sigma(X W  + b) = \\frac{1}{ 1 + e^{-(X W  + b)}}$. Esta función devuelve, además de la activación resultante, la variable cache que contiene la señal `S` que dio lugar a la activación (se utiilza luego durante la propagación hacia atrás).\n",
    "\n",
    "``` python\n",
    "X, cache = sigmoid(S)\n",
    "```\n",
    "\n",
    "\n",
    "- **Rectified Linear Unit**:  $ReLU(S) = \\max(0, S)$.  Al igual que en el caso de la activación sigmoide, esta función devuelve además de la activación resultante, la variable cache que contiene la señal `S` que dio lugar a la activación (se utiilza luego durante la propagación hacia atrás).\n",
    "\n",
    "``` python\n",
    "X, cache = relu(Z)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(S):\n",
    "    \"\"\"\n",
    "    Implementa la activación sigmoide\n",
    "    \n",
    "    Entrada:\n",
    "        S: arreglo numpy que contiene las entradas a la activación. \n",
    "           Las dimensiones de entrada no están definidas.\n",
    "    \n",
    "    Salida:\n",
    "        X: arreglo del mismo tamaño que S que contiene la salida de sigmoid(S) \n",
    "    cache: devuelve S para utilizar durante la propagación hacia atrás\n",
    "    \"\"\"\n",
    "\n",
    "    X = 1/(1+np.exp(-S))\n",
    "    cache = S\n",
    "\n",
    "    assert X.shape == S.shape, 'La entrada y la salida deben ser del mismo tamaño'\n",
    "    return X, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(S):\n",
    "    '''\n",
    "    Implementa la activación relu\n",
    "    \n",
    "    Entrada:\n",
    "        S: arreglo numpy que contiene las entradas a la activación. \n",
    "           Las dimensiones de entrada no están definidas.\n",
    "    \n",
    "    Salida:\n",
    "        X: arreglo del mismo tamaño que S que contiene la salida de relu(S) \n",
    "    cache: devuelve S para utilizar durante la propagación hacia atrás\n",
    "    '''\n",
    "    \n",
    "    X = np.maximum(0,S)\n",
    "    \n",
    "    assert(X.shape == S.shape)\n",
    "    cache = S \n",
    "        \n",
    "    return X, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Aplicación conjunta de capa afin y activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se provee la implementación de la propagación hacia adelante de una capa *Afin->Activacion*. El método `afin_activacion_forward()` implementa la operación:\n",
    "\n",
    "$$\n",
    "X^{[l]} = \\theta(S^{(l)}) = \\theta(X^{(l-1)}W^{(l)} +b^{(l)})\n",
    "$$\n",
    "\n",
    "donde la activación $\\theta(\\cdot)$ será alguna de las implementadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_activacion_forward(X_prev, W, b, activacion):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia adelante para una capa Afin->Activación \n",
    "    Entrada:\n",
    "        X_prev: arreglo de tamaño (N, dim capa anterior) que contiene la \n",
    "                activación de la capa anterior (o datos de entrada):          \n",
    "        W: matriz de pesos de tamaño (dim de capa anterior, dim de capa actual)  \n",
    "        b: vector de bias de tamaño (dim de la capa actual)\n",
    "        activacion: la activacion a utilizar en esta capa se indica con uno de los \n",
    "                    siguientes strings: 'sigmoide', 'tanh' o 'relu'\n",
    "\n",
    "    Salida:\n",
    "        X: arreglo de tamaño (N, dim de capa actual) que contiene la salida \n",
    "           de la función de activación  \n",
    "    cache: tupla que contiene \"cache_afin\" y \"cache_activacion\".\n",
    "           Se almacenan para calcular la propagación hacia atrás eficientemente\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    S, cache_afin = afin_forward(X_prev,W,b)\n",
    "    \n",
    "    if activacion == 'sigmoide':    \n",
    "        \n",
    "        X, cache_activacion = sigmoide(S)\n",
    "    \n",
    "    elif activacion == 'relu':\n",
    "        \n",
    "        X, cache_activacion = relu(S)\n",
    "    \n",
    "    assert (X.shape == (X_prev.shape[0], W.shape[1]))\n",
    "    cache = (cache_afin, cache_activacion)\n",
    "\n",
    "    return X, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Función de costo\n",
    "\n",
    "En esta sección se implementarán dos funciones de costo.  \n",
    "\n",
    "- **Entropía cruzada:** Es la función de costo más utilizada en problemas de clasificación binaria. Se recuerda que la misma se define mediante la fórmula:\n",
    "$$\n",
    "H(\\mathbf{\\mathbf{x}^{(L)}}, \\mathbf{y})= -\\frac{1}{N} \\sum\\limits_{n = 1}^{N} \\left( y_n\\log x^{(L)}_n + (1-y_n)\\log\\left(1- x^{(L)}_n\\right) \\right) \\tag{3}\n",
    "$$\n",
    "\n",
    "- **Entropía cruzada regularizada:** Es la versión regularizada de la *entropía cruzada* definida anteriormente:\n",
    "$$\n",
    "H_{reg}(\\mathbf{\\mathbf{x}^{(L)}}, \\mathbf{y})= -\\frac{1}{N} \\sum\\limits_{n = 1}^{N} \\left( y_n\\log x^{(L)}_n + (1-y_n)\\log\\left(1- x^{(L)}_n\\right) \\right) + \\frac{1}{2N}\\sum_{l=1}^{L} \\Vert W_l \\Vert_2^2 \\tag{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte b) \n",
    "Implementar el método `entropia_cruzada_regularizada()`. De manera similar a la implementación de `entropia_cruzada()` provista, la función deberá devolver, además del costo, el gradiente del costo respecto al vector $\\mathbf{x}^{(L)}$ (salida de la red y entrada del bloque *Loss*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia_cruzada(xL, y):\n",
    "    \"\"\"\n",
    "    Implementa la entropía cruzada\n",
    "\n",
    "    Entrada:\n",
    "        xL: vector de dimensión (N,1) que contiene las ¨probabilidades¨ de pertenecer a la clase positiva \n",
    "            estimadas por el modelo\n",
    "        y: vector de etiquetas de dimesión (N,1) (con unos para la clase positiva y 0 para la negativa)\n",
    "\n",
    "    Salida:\n",
    "        costo: escalar con el costo calculado\n",
    "        dxL: gradiente del costo respecto a xL, tiene las mismas dimensiones que xL\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(y)\n",
    "\n",
    "    logprobs = np.log(xL) * y + (1 - y) * np.log(1 - xL)\n",
    "    costo = -np.mean(logprobs)\n",
    "    \n",
    "    dxL = -(np.divide(y, xL) - np.divide(1 - y, 1 - xL))/N\n",
    "\n",
    "    costo = np.squeeze(costo) # Para asegurarnos que la salida sea un escalar (Ej: transforma [[12]] en 12).\n",
    "    assert(costo.shape == ())\n",
    "    assert(dxL.shape == xL.shape), 'Las dimensiones de dxL y xL deben ser iguales'\n",
    "    return costo, dxL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia_cruzada_regularizada(xL, y, parametros, factor_reg):\n",
    "    \"\"\"\n",
    "    Implementa la entropía cruzada\n",
    "\n",
    "    Entrada:\n",
    "        xL: vector de dimensión (N,1) que contiene las ¨probabilidades¨ de pertenecer a la clase positiva \n",
    "            estimadas por el modelo\n",
    "        y: vector de etiquetas de dimesión (N,1) (con unos para la clase positiva y 0 para la negativa)\n",
    "        parametros: diccionario python que contiene los parametros de la red\n",
    "        factor_reg: factor de regularización\n",
    "\n",
    "    Salida:\n",
    "        costo: escalar con el costo calculado (tomando en cuenta la regularización)\n",
    "        dxL: gradiente del costo respecto a xL, tiene las mismas dimensiones que xL\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(y)\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    # Calculo el costo\n",
    "    \n",
    "    costo_aux = 0\n",
    "    for n in range(N):\n",
    "        costo_aux = costo_aux + (y[n]*np.log(xL[n]) + (1 - y[n])*np.log(1-xL[n])) \n",
    "\n",
    "    costo = -costo_aux/N #guardo el primer sumando del costo\n",
    "    costo_aux = 0\n",
    "    \n",
    "    L = 3\n",
    "    for l in range(1,L+1):\n",
    "        costo_aux += np.linalg.norm(parametros['W' + str(l)])**2 \n",
    "    \n",
    "    costo += factor_reg*costo_aux/(2*N)\n",
    "    \n",
    "    # Calculo dxL\n",
    "    \n",
    "    dxL_aux = np.zeros_like(xL)\n",
    "    for n in range(N):\n",
    "        dxL_aux[n] += (-y[n]/xL[n] + (1 - y[n])/(1-xL[n])) \n",
    "        \n",
    "    dxL = dxL_aux/N #guardo el primer sumando del costo\n",
    "\n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    costo = np.squeeze(costo) # Para asegurarnos que la salida sea un escalar (Ej: transforma [[12]] en 12).\n",
    "    assert(costo.shape == ())\n",
    "    assert(dxL.shape == xL.shape), 'Las dimensiones de dxL y xL deben ser iguales'\n",
    "    return costo, dxL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing entropia_cruzada:\n",
      "costo:  1.1244552259459768\n",
      "error en dP:  1.0993162320064296e-08\n"
     ]
    }
   ],
   "source": [
    "# Se testea la implementación de la entropía cruzada regularizada\n",
    "np.random.seed(231)\n",
    "num_classes, num_inputs = 2, 10\n",
    "xL_ = np.random.rand(num_inputs,1)\n",
    "y_ = np.random.randint(num_classes, size=(num_inputs,1))\n",
    "W1_ = np.random.randn(5, 3)\n",
    "W2_ = np.random.randn(3, 4)\n",
    "W3_ = np.random.randn(4, 1)\n",
    "param={'W1':W1_,'W2':W2_,'W3':W3_}\n",
    "lambd = 0.1\n",
    "\n",
    "dxL_num = calcular_gradiente_numerico(lambda xL: entropia_cruzada_regularizada(xL, y_, param, lambd)[0],\n",
    "                                                 xL_, verbose=False)\n",
    "costo, dxL = entropia_cruzada_regularizada(xL_, y_,  param, lambd)\n",
    "\n",
    "# Testing la entropía cruzada regularizada. El costo debería dar cercano a 1.12 y el error en dP alrededor de 1e-8\n",
    "print('\\nTesting entropia_cruzada:')\n",
    "print('costo: ', costo)\n",
    "print('error en dP: ', error_relativo(dxL_num, dxL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Propagación hacia atrás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementará la versión *backward* de cada una de las funciones *forward* implementadas anteriormente. A saber:\n",
    "- AFIN backward\n",
    "- ACTIVACION backward \n",
    "- AFIN -> ACTIVACION backward donde ACTIVACION puede ser *ReLU* o *sigmoide* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Afin backward\n",
    "\n",
    "Durante la propagación hacia adelante en la capa $l$ (sin considerar la activación) se calcula para una muestra: \n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(l)}=\\left( W^{(l)} \\right)^T \\mathbf{x}^{(l-1)}+ \\mathbf{b}^{(l)}   \\tag{1}\n",
    "$$\n",
    "\n",
    "Si se llama $e_n$ al costo debido a la muesta $n$ y se asume conocido el *vector de sensibilidad* $\\delta^{(l)}=\\frac{\\partial e_n}{\\partial \\mathbf{s}^{(l)}}$, en el teórico del curso se vio que \n",
    "\n",
    "$$\n",
    "\\frac{\\partial{e_n}}{\\partial{W^{(l)}}}=\\mathbf{x}^{(l-1)} \\left( \\delta^{(l)} \\right)^T\n",
    "$$\n",
    "\n",
    "Análogamente a como se hizo en el caso de la propagación hacia adelante, si se considera la contribución al error de un conjunto de muestras a la vez la ecuación se puede escribir en forma vectorizada como:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{E}}{\\partial{W^{(l)}}}= dW^{(l)} = \\left( X^{(l-1)}\\right)^ T dS^{(l)}   \\tag{5}\n",
    "$$\n",
    "\n",
    "donde $dS^{(l)}$ es una matríz de tamaño $N\\times d^{(l)}$ que en cada fila contiene el vector de sensibilidad $\\delta^{(l)}_n$ correspondiente a una de las muestras.\n",
    "\n",
    "Las derivadas respecto al vector de bias $\\mathbf{b}^{(l)}$ se calculan de forma similar (puede pensarse como un caso particular en que $X^{(l-1)}$ es un vector columna de unos) por lo que\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{E}}{\\partial{\\mathbf{b}^{(l)}}}= d\\mathbf{b}^{(l)} =\\mathbb{1} ^ T dS^{(l)}  \\tag{6}\n",
    "$$\n",
    "\n",
    "Finalmente se calcula la influencia de cada una de las características en el error. Considerando primero el caso de una muestra, se tiene que:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{e_n}}{\\partial{\\mathbf{x}^{(l-1)}}} = W^{(l)} \\delta^{(l)}\n",
    "$$\n",
    "\n",
    "que en forma vectorizada puede escribirse como:\n",
    "\n",
    "$$ \n",
    " \\frac{\\partial E }{\\partial X^{(l-1)}} = dX^{(l-1)} = dS^{(l)} \\left( W^{(l) }\\right)^T \\tag{7}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte c) \n",
    "Implementar el método `afin_backward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_backward(dS, cache):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia atrás para una capa l (sin considerar la activación)\n",
    "\n",
    "    Entrada:\n",
    "        dS: Gradiente de la función de costo con respecto a la salida de la capa actual \n",
    "            (sin considerar la activación)\n",
    "        cache: tupla de valores (X_prev, W, b) calculados durante la propagación hacia adelante\n",
    "               de la capa actual\n",
    "\n",
    "    Salida:\n",
    "        dX_prev: Gradiente de la función de costo con respecto a la activación de la capa anterior (l-1), \n",
    "                 tiene el mismo tamaño que X_prev\n",
    "        dW: Gradiente de la función de costo con respecto a W (de la capa actual l), \n",
    "            tiene el mismo tamaño que W\n",
    "        db: Gradiente de la función de costo con respecto a b (de la capa actual l), \n",
    "            tiene el mismo tamaño que b\n",
    "    \"\"\"\n",
    "    X_prev, W, b = cache\n",
    "    N = X_prev.shape[0]\n",
    "\n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    dX_prev = dS@np.transpose(W)\n",
    "    \n",
    "    dW = np.transpose(X_prev)@dS\n",
    "    \n",
    "    unos = np.ones((dS.shape[0]))\n",
    "    db = unos@dS\n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    assert (dX_prev.shape == X_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dX_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing afin_backward():\n",
      "dx error:  3.669042497648924e-09\n",
      "dw error:  3.7482312588464514e-11\n",
      "db error:  1.640806364146397e-11\n"
     ]
    }
   ],
   "source": [
    "# Test de afin_backward\n",
    "np.random.seed(43)\n",
    "x = np.random.randn(10, 6)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "#dx_num = calcular_gradiente_numerico_array(lambda x: afin_forward(x, w, b)[0], x, dout)\n",
    "dx_num = calcular_gradiente_numerico_array(lambda xx: afin_forward(xx, w, b)[0], x, dout)\n",
    "\n",
    "dw_num = calcular_gradiente_numerico_array(lambda ww: afin_forward(x, ww, b)[0], w, dout)\n",
    "db_num = calcular_gradiente_numerico_array(lambda bb: afin_forward(x, w, bb)[0], b, dout)\n",
    "\n",
    "_, cache = afin_forward(x, w, b)\n",
    "dx, dw, db = afin_backward(dout, cache)\n",
    "\n",
    "# El error debería ser del orden de e-9 o menos\n",
    "print('Testing afin_backward():')\n",
    "print('dx error: ', error_relativo(dx_num, dx))\n",
    "print('dw error: ', error_relativo(dw_num, dw))\n",
    "print('db error: ', error_relativo(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Activación backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si  $\\theta(\\cdot)$ es la función de activación, entonces su función *backward* se calcula \n",
    "\n",
    "$$\n",
    "dS^{(l)} = dX^{(l)} * \\theta'(S^{(l)})   \\tag{8}\n",
    "$$.  \n",
    "\n",
    "donde $\\theta'(\\cdot)$ debe ser calculado para cada caso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte d) \n",
    "Implementar los métodos *backward* cada una de las funciones de activación implementadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide_backward(dX, cache):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia atrás de una activación Sigmoide.\n",
    "\n",
    "    Entrada:\n",
    "        dX: gradiente de la función de costo respecto a la salida de la capa relu,\n",
    "              el tamaño del arreglo no está definido\n",
    "        cache: 'S' valor almacenado durante la propagación hacia adelante\n",
    "\n",
    "    Returns:\n",
    "    dS -- Gradiente del costo respecto a S\n",
    "    \"\"\"\n",
    "    \n",
    "    S = cache\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    theta = 1/(1+np.exp(-S))\n",
    "    \n",
    "    theta_prima = np.exp(-S)*(theta**2)\n",
    "    \n",
    "    dS = dX*theta_prima\n",
    "    \n",
    "    \n",
    "     \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    assert (dS.shape == S.shape), 'dS y S no tienen el mismo tamaño'\n",
    "    assert (dX.shape == S.shape), 'dX y S no tienen el mismo tamaño'\n",
    "    \n",
    "    return dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward():\n",
      "dS error:  3.44651192693257e-11\n"
     ]
    }
   ],
   "source": [
    "# Test de sigmoid_backward\n",
    "np.random.seed(231)\n",
    "S = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*S.shape)\n",
    "\n",
    "dS_num = calcular_gradiente_numerico_array(lambda S: sigmoide(S)[0], S, dout)\n",
    "\n",
    "_, cache = sigmoide(S)\n",
    "dS = sigmoide_backward(dout, cache)\n",
    "\n",
    "# El error debería ser del orden de e-10 o menos\n",
    "print('Testing relu_backward():')\n",
    "print('dS error: ', error_relativo(dS_num, dS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dX, cache):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia atrás de una activación ReLu.\n",
    "\n",
    "    Entrada:\n",
    "        dX: gradiente de la función de costo respecto a la salida de la capa relu,\n",
    "              el tamaño del arreglo no está definido\n",
    "        cache: 'S' valor almacenado durante la propagación hacia adelante\n",
    "\n",
    "    Returns:\n",
    "    dS -- Gradiene del costo respecto a S\n",
    "    \"\"\"\n",
    "    \n",
    "    S = cache\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    dS = np.zeros_like(S)\n",
    "    theta = np.maximum(0,S)\n",
    "    theta_prima = np.zeros_like(S)\n",
    "    \n",
    "    for i in range(theta.shape[0]):\n",
    "        for j in range(theta.shape[1]):\n",
    "            if theta[i,j] > 0:\n",
    "                theta_prima[i,j] = 1\n",
    "    \n",
    "    \n",
    "    dS = dX*theta_prima\n",
    "    \n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    assert (dS.shape == S.shape)\n",
    "    \n",
    "    return dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward():\n",
      "dS error:  3.2756349136310288e-12\n"
     ]
    }
   ],
   "source": [
    "# Test de relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dS_num = calcular_gradiente_numerico_array(lambda x: relu(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu(x)\n",
    "dS = relu_backward(dout, cache)\n",
    "\n",
    "# El error debería ser del orden de e-12\n",
    "print('Testing relu_backward():')\n",
    "print('dS error: ', error_relativo(dS_num, dS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Afin --> Activacion backward\n",
    "\n",
    "A continuación se implementará la función que realiza la propagación hacia atrás del la capa *Afin-->Activacion*. \n",
    "\n",
    "### Parte e) \n",
    "Implementar la función `afin_activacion_backward()`. Para ello utilizar las funciones implementadas anteriormente: `afin_backward` y la ¨`activacion_backward`¨ que corresponda. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_activacion_backward(dX, cache, activacion):\n",
    "    '''\n",
    "    Implementar la propagación hacia atrás para la capa Afin->Activacion.\n",
    "    \n",
    "    Entradas:\n",
    "        dX: gradiente del costo respecto a la salida de la capa actual \n",
    "        cache: tupla con los valores(cache_afin, cache_activacion) \n",
    "        activacion: la activación a utilizar en esta capa, puede ser 'sigmoide' o 'relu'\n",
    "    Salidas:\n",
    "        dX_prev: Gradiente del costo con respecto a la activación de la capa anterior(l-1), \n",
    "                 tiene las mismas dimensiones que X_prev\n",
    "        dW -- Gradiente del costo con respecto a W (de la capa actual l), \n",
    "              tiene las mismas dimensiones que W\n",
    "        db -- Gradiente del costo con respecto a b (de la capa actual l), \n",
    "              tiene las mismas dimensiones que b\n",
    "    '''\n",
    "    cache_afin, cache_activacion = cache\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    \n",
    "    if activacion == 'relu':\n",
    "        dS = relu_backward(dX, cache_activacion)\n",
    "        dX_prev, dW, db = afin_backward(dS, cache_afin)\n",
    "    elif activacion == 'sigmoide':\n",
    "        dS = sigmoide_backward(dX, cache_activacion)\n",
    "        dX_prev, dW, db = afin_backward(dS, cache_afin)\n",
    "\n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    return dX_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing afin_relu_forward y afin_relu_backward:\n",
      "dx error:  2.299579177309368e-11\n",
      "dw error:  8.162011105764925e-11\n",
      "db error:  7.826724021458994e-12\n",
      "Testing afin_sigmoide_forward y afin_sigmoide_backward:\n",
      "dx error:  1.2457001345560838e-10\n",
      "dw error:  2.782128735145574e-09\n",
      "db error:  1.5238194515875374e-10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 12)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "activaciones = ['relu', 'sigmoide']\n",
    "\n",
    "for activacion in activaciones:\n",
    "    out, cache = afin_activacion_forward(x, w, b, activacion)\n",
    "    dx, dw, db = afin_activacion_backward(dout, cache, activacion)\n",
    "\n",
    "    dx_num = calcular_gradiente_numerico_array(lambda x: afin_activacion_forward(x, w, b, activacion)[0], x, dout)\n",
    "    dw_num = calcular_gradiente_numerico_array(lambda w: afin_activacion_forward(x, w, b, activacion)[0], w, dout)\n",
    "    db_num = calcular_gradiente_numerico_array(lambda b: afin_activacion_forward(x, w, b, activacion)[0], b, dout)\n",
    "\n",
    "    # Los errores deberían ser del orden de e-9 o menos\n",
    "    print('Testing afin_' + activacion + '_forward y afin_' + activacion + '_backward:')\n",
    "    print('dx error: ', error_relativo(dx_num, dx))\n",
    "    print('dw error: ', error_relativo(dw_num, dw))\n",
    "    print('db error: ', error_relativo(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5 - Actualización de los parámetros\n",
    "\n",
    "En esta sección se actualizarán los parámetros del modelo mediante el método de *descenso por gradiente*:\n",
    "\n",
    "$$ W^{(l)} = W^{(l)} -\\eta \\text{ } dW^{(l)} \\tag{9}$$\n",
    "$$ \\mathbf{b}^{(l)} = \\mathbf{b}^{(l)} -\\eta \\text{ } \\mathbf{db}^{(l)} \\tag{10}$$\n",
    "\n",
    "donde $\\eta$ es el *learning rate*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte f) \n",
    "Implementar `actualizar_parametros()` para actualizar los parámetros usando *descenso por gradiente*. Luego de actualizar los parámetros, almacenarlos en el diccionario de parámetros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_parametros(parametros, gradientes, learning_rate):\n",
    "    \"\"\"\n",
    "    Se actualizan los parámetros utilizando descenso por gradiente. Si bien en este notebook se trabaja \n",
    "    con una red de dos capas, el método se implementa en forma genérica para mostrar como se haría en el\n",
    "    caso más general.\n",
    "    \n",
    "    Entrada:\n",
    "        parametros: diccionario de python que contiene los parámetros \n",
    "        gradientes: diccionario de python que contiene los gradientes \n",
    "                    (las salidas de los métodos backward)\n",
    "    \n",
    "    Salida:\n",
    "        parametros: diccionario de python que contiene los parámetros actualizados \n",
    "                    parametros[\"W\" + str(l)] = ... \n",
    "                    parametros[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parametros) // 2 # número de capas en la red neuronal\n",
    "    \n",
    "    # Se actualiza cada uno de los parámetros. En el caso de una red profunda de L capas\n",
    "    # se hace con un loop que va recorriendo cada parámetro\n",
    "    for l in range(1,L+1):\n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "        \n",
    "        parametros[\"W\" + str(l)] = parametros[\"W\" + str(l)] - learning_rate*gradientes[\"dW\" + str(l)]\n",
    "        parametros[\"b\" + str(l)] = parametros[\"b\" + str(l)] - learning_rate*gradientes[\"db\" + str(l)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación utilizando datos sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aux_datos import load_2D_dataset, mostrar_frontera_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan datos sintéticos con forma de flor pertenecientes a dos clases: $cero$ y $uno$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 2) (211, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_2D_dataset()\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se muestran los datos\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=Y_train.ravel(), s=40, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red para clasificar los datos sintéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para clasificar los datos sintéticos se utilizará una red de **tres capas** con la siguiente arquitectura:   \n",
    "\n",
    "*Afin->Relu->Afin->Relu-->Afin-->Sigmoide* \n",
    "\n",
    "### Parte g)  \n",
    "Completar la implementación del método `red_tres_capas()` utilizando los métodos *forward* y *backward* adecuados para dicha arquitectura. Como función de costo se utilizará la *entropía cruzada*.\n",
    "\n",
    "**Nota:** La función tiene previsto un parámetro para indicar si se aplica o no regularización y otro parámetro para el factor de regularización. En esta parte no hay que utilizar ninguno de estos parámetros, o bien asumir que `regularizar` es `False`. La regularización se implementará en una parte posterior.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_tres_capas(X, Y, dims_capas, num_iter = 1000, learning_rate = 1,\n",
    "                    mostrar_costo=False, semilla=100, regularizar=False, reg_factor=1):\n",
    "    \"\"\"\n",
    "    Implementa una red neuronal de dos capas: Afin->Relu->Afin->Sigmoide.\n",
    "    \n",
    "    Entrada:\n",
    "        X: datos de entrada, de tamaño (N, d_0)\n",
    "        Y: etiquetas (1 para la clase positiva y 0 para la negativa), de tamaño (N,1)\n",
    "        dims_capas: dimensiones de las capas(d_0, d_1, d_2)\n",
    "        num_iter: número de iteraciones del loop de optimización\n",
    "        learning_rate: learning rate utilizado para la actualización mediante descenso por gradiente\n",
    "        mostrar_costo: Si vale True, se muestra el costo cada 100 iteraciones \n",
    "        semilla: semilla utilizada para la generación de números aleatorios\n",
    "        regularizar: indica si se aplica o no regularización\n",
    "        reg_factor: factor de regularización\n",
    "    Salida:\n",
    "        parametros: un diccionario de python que contiene W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(semilla)\n",
    "    gradientes = {} # se inicializa el diccionario que almacena los gradientes\n",
    "    costos = []     # lista que almacena el costo\n",
    "    N = X.shape[0]  # número de muestras\n",
    "    \n",
    "    # Se inicializan los parámetros del diccionario llamando a una de las \n",
    "    # funciones previamente implementadas\n",
    "    parametros = inicializar_pesos(dims_capas, semilla=semilla)\n",
    "     \n",
    "    # Se obtienen W1, b1, W2 y b2 del diccionario de parámetros.\n",
    "    W1 = parametros[\"W1\"]\n",
    "    b1 = parametros[\"b1\"]\n",
    "    W2 = parametros[\"W2\"]\n",
    "    b2 = parametros[\"b2\"]\n",
    "    W3 = parametros[\"W3\"]\n",
    "    b3 = parametros[\"b3\"]\n",
    "    # Loop (descenso por gradiente)\n",
    "\n",
    "    for i in range(0, num_iter):\n",
    "\n",
    "        ####################################################################################\n",
    "        ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "        \n",
    "        # Propagación hacia adelante: Afin -> Relu -> Afin -> Relu -> Afin -> Sigmoide. \n",
    "        # Entradas: \"X, W1, b1\". Salidas: \"X1, cache1, X2, cache2, X3, cache3\".\n",
    "        X1, cache1 = afin_activacion_forward(X, W1, b1, 'relu')\n",
    "        X2, cache2 = afin_activacion_forward(X1, W2, b2, 'relu')\n",
    "        X3, cache3 = afin_activacion_forward(X2, W3, b3, 'sigmoide')\n",
    "        \n",
    "        # Se calcula el costo y se inicia la propagación hacia atrás\n",
    "        costo, dxL = entropia_cruzada_regularizada(X3, Y, parametros, factor_reg=1)\n",
    "        \n",
    "        \n",
    "        # Propagación hacia atrás. \n",
    "        # Entradas: \"dX3, cache3, cache2, cache1\". \n",
    "        # Salidas: \"dX2, dW3, db3, dX1, dW2, db2, dW1, db1, dX0 (no utilizado)\".\n",
    "        dX2, dW3, db3 = afin_activacion_backward(dxL, cache3, 'sigmoide')\n",
    "        dX1, dW2, db2 = afin_activacion_backward(dX2, cache2, 'relu')\n",
    "        dX0, dW1, db1 = afin_activacion_backward(dX1, cache1, 'relu')\n",
    "        \n",
    "        # Se almacenan los gradientes recientemente calculados en el diccionario \n",
    "        gradientes = {'dW1': dW1,\n",
    "                      'db1': db1,\n",
    "                      'dW2': dW2,\n",
    "                      'db2': db2,\n",
    "                      'dW3': dW3,\n",
    "                      'db3': db3}\n",
    "        \n",
    "        \n",
    "        # Se actualizan los parámetros\n",
    "        parametros = actualizar_parametros(parametros, gradientes, learning_rate)\n",
    "        \n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "\n",
    "        # Se obtienen los nuevos W1, b1, W2, b2, W3 y b3 del diccionario de parámetros.        \n",
    "        W1 = parametros[\"W1\"] \n",
    "        b1 = parametros[\"b1\"]\n",
    "        W2 = parametros[\"W2\"]\n",
    "        b2 = parametros[\"b2\"]\n",
    "        W3 = parametros[\"W3\"]\n",
    "        b3 = parametros[\"b3\"]\n",
    "\n",
    "        \n",
    "        # Se muestra la evolución del costo cada 100 iteraciones\n",
    "        if mostrar_costo and i % 1000 == 0:\n",
    "            print(\"Costo luego de iteracion {}: {}\".format(i, np.squeeze(costo)))\n",
    "\n",
    "        if mostrar_costo and i % 1000 == 0:\n",
    "            costos.append(costo)\n",
    "    \n",
    "    # se muestra el costo\n",
    "    if mostrar_costo:    \n",
    "        plt.plot(np.squeeze(costos))\n",
    "        plt.ylabel('costo')\n",
    "        plt.xlabel('iteraciones (sobre 100)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Se definen las constantes que determinan la arquitectura de la red ####\n",
    "d_0 = X_train.shape[1]   \n",
    "d_1 = 20\n",
    "d_2 = 3\n",
    "d_3 = 1\n",
    "#dims_capas = [d_0, d_1, d_2, d_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo luego de iteracion 0: 0.7096181949695461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in multiply\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:42: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in exp\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: overflow encountered in exp\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-1f24fa24990a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m parametros_red_3capas = red_tres_capas(X_train, Y_train, dims_capas = [d_0, d_1, d_2, d_3], \n\u001b[1;32m      4\u001b[0m                                     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m38000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmostrar_costo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                     regularizar=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-123-b7a421f0974d>\u001b[0m in \u001b[0;36mred_tres_capas\u001b[0;34m(X, Y, dims_capas, num_iter, learning_rate, mostrar_costo, semilla, regularizar, reg_factor)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafin_activacion_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdxL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sigmoide'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafin_activacion_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mdX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafin_activacion_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Se almacenan los gradientes recientemente calculados en el diccionario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-56b59a60a20a>\u001b[0m in \u001b[0;36mafin_activacion_backward\u001b[0;34m(dX, cache, activacion)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivacion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_activacion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mdX_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafin_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_afin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivacion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sigmoide'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-19b60ef29a78>\u001b[0m in \u001b[0;36mrelu_backward\u001b[0;34m(dX, cache)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mtheta_prima\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Se entrena la red, con los parámetros por defecto el costo debería ser alrededor de 0.65 en la iteración 0 y \n",
    "# menor a 0.15 en la 20000\n",
    "parametros_red_3capas = red_tres_capas(X_train, Y_train, dims_capas = [d_0, d_1, d_2, d_3], \n",
    "                                    learning_rate = 0.2, num_iter = 38000, mostrar_costo=True,\n",
    "                                    regularizar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBS: Me esta dando nan y me quedé sin tiempo para depurar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar la frontera de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte h)  \n",
    "Mostrar la frontera de decisión. Para ello se deberá completar primero la implementación del método `predecir_clase_datos_sinteticos()`. Dicho método utiliza los parámetros de la red recientemente encontrados para predecir la clase de los vectores de características pasados como parámetro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_clase_datos_sinteticos(X, parametros):\n",
    "    \"\"\"\n",
    "    Esta función predice la clase de los datos sintéticos. \n",
    "    \n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nx2 que en cada fila contiene un vector de características\n",
    "        parametros: parametros del modelo ya entrenado\n",
    "    \n",
    "    Salida:\n",
    "        p : vector de tamaño Nx1 que contiene las predicciones realizadas (0 o 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Se obtienen W1, b1, W2, b2, W3 y b3 del diccionario de parámetros.\n",
    "    W1 = parametros[\"W1\"]\n",
    "    b1 = parametros[\"b1\"]\n",
    "    W2 = parametros[\"W2\"]\n",
    "    b2 = parametros[\"b2\"]\n",
    "    W3 = parametros[\"W3\"]\n",
    "    b3 = parametros[\"b3\"]\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    p = np.zeros((N,1))\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    # Se hace la propagación hacia adelante de los datos de entrada X. Tener en cuenta que la\n",
    "    # arquitectura utilizada en la red fue Afin-->Relu-->Afin-->Relu-->Afin-->Sigmoide\n",
    "    # ~ 3 lineas de codigo\n",
    "\n",
    "    \n",
    "    # Se obtienen las predicciones. Si la salida es mayor que 0.5 se asigna la clase 1, de lo \n",
    "    # contrario se asigna 0\n",
    "    # ~ 1 linea de codigo\n",
    "\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda muestra el porcentaje de acierto con el conjunto de entrenamiento. Verificar que para los parámetros por defecto es mayor al 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_train = predecir_clase_datos_sinteticos(X_train, parametros_red_3capas)\n",
    "porcentaje_aciertos = np.mean(predicciones_train==Y_train)\n",
    "print('El porcentaje de aciertos es %f' % porcentaje_aciertos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra la frontera de decisión. Verificar que es razonable para el conjunto de entrenamiento.\n",
    "mostrar_frontera_decision(lambda x: predecir_clase_datos_sinteticos(x, parametros_red_3capas), X_train, Y_train.flatten())\n",
    "plt.title('Frontera de decisión para una capa oculta de ' + str(d_1) + ' nodos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte i)\n",
    "Modificar la implementación de `red_tres_capas()` de modo que cuando se pase como parámetro `regularizar=True` utilice como función de costo `entropia_cruzada_regularizada()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Con regularización\n",
    "parametros_red_3capas_regularizada = red_tres_capas(X_train, Y_train, dims_capas = [d_0, d_1, d_2, d_3], \n",
    "                                                    learning_rate = 0.2, num_iter = 38000, mostrar_costo=True,\n",
    "                                                    regularizar=True, reg_factor=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_train = predecir_clase_datos_sinteticos(X_train, parametros_red_3capas_regularizada)\n",
    "porcentaje_aciertos = np.mean(predicciones_train==Y_train)\n",
    "print('El porcentaje de aciertos es %f' % porcentaje_aciertos)\n",
    "\n",
    "# Se muestra la frontera de decisión. Verificar que es razonable para el conjunto de entrenamiento.\n",
    "mostrar_frontera_decision(lambda x: predecir_clase_datos_sinteticos(x, parametros_red_3capas_regularizada), X_train, Y_train.flatten())\n",
    "plt.title('Frontera de decisión para una capa oculta de ' + str(d_1) + ' nodos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte j)\n",
    "¿Considera que el valor por defecto (1e-3) del factor de regularización es adecuado? Comente como influye este factor en la solución y cómo eligiría su valor más adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
